{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üìã Padr√µes GoF no LangExtract\n",
        "\n",
        "## üéØ 5 Padr√µes Identificados\n",
        "\n",
        "| # | Padr√£o | Arquivo | GoF | O que faz |\n",
        "|---|--------|---------|-----|-----------|\n",
        "| 1 | **Factory** | `factory.py` | ‚ö†Ô∏è | Cria providers (Gemini/OpenAI/Ollama) via `create_model()` |\n",
        "| 2 | **Iterator** | `chunking.py` | ‚úÖ | Itera documentos grandes com `ChunkIterator.__next__()` |\n",
        "| 3 | **Facade** | `extraction.py` | ‚úÖ | Fun√ß√£o `extract()` oculta 6 subsistemas |\n",
        "| 4 | **Builder** | `prompting.py` | ‚ö†Ô∏è | `QAPromptGenerator.render()` constr√≥i prompts em 6 passos |\n",
        "| 5 | **Strategy** | `base_model.py` | ‚úÖ | `BaseLanguageModel` interface, 3 algoritmos (Gemini/OpenAI/Ollama) |\n",
        "\n",
        "**Legenda:** ‚úÖ 100% GoF | ‚ö†Ô∏è Varia√ß√£o simplificada\n",
        "\n",
        "---\n",
        "\n",
        "## üìù Evid√™ncias\n",
        "\n",
        "### 1. Factory (`factory.py`)\n",
        "```python\n",
        "def create_model(config) -> BaseLanguageModel:\n",
        "    provider_cls = router.resolve(config.model_id)\n",
        "    return provider_cls(**kwargs)  # Retorna Gemini/OpenAI/Ollama\n",
        "```\n",
        "\n",
        "### 2. Iterator (`chunking.py`)\n",
        "```python\n",
        "class ChunkIterator:\n",
        "    def __next__(self) -> Chunk:\n",
        "        if not self._has_more:\n",
        "            raise StopIteration\n",
        "        return self._get_next_chunk()\n",
        "```\n",
        "\n",
        "### 3. Facade (`extraction.py`)\n",
        "```python\n",
        "def extract(...):\n",
        "    model = create_model(...)      # Factory\n",
        "    prompt = QAPromptGenerator()   # Builder\n",
        "    return Annotator(model).annotate(...)  # Strategy\n",
        "```\n",
        "\n",
        "### 4. Builder (`prompting.py`)\n",
        "```python\n",
        "def render(question):\n",
        "    lines = []\n",
        "    lines.append(description)       # Passo 1\n",
        "    lines.append(context)           # Passo 2\n",
        "    lines.append(examples)          # Passo 3\n",
        "    lines.append(question)          # Passo 4\n",
        "    return \"\\n\".join(lines)\n",
        "```\n",
        "\n",
        "### 5. Strategy (`base_model.py` + providers)\n",
        "```python\n",
        "class BaseLanguageModel(ABC):\n",
        "    @abstractmethod\n",
        "    def infer(...): pass\n",
        "\n",
        "class GeminiLanguageModel(BaseLanguageModel):\n",
        "    def infer(...): # google-genai SDK\n",
        "\n",
        "class OpenAILanguageModel(BaseLanguageModel):\n",
        "    def infer(...): # openai SDK\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ÔøΩ Documenta√ß√£o Detalhada\n",
        "\n",
        "1. `factory_pattern_analysis.md`\n",
        "2. `iterator_pattern_analysis.md`\n",
        "3. `facade_pattern_analysis.md`\n",
        "4. `builder_pattern_analysis.md`\n",
        "5. `strategy_pattern_analysis.md`\n",
        "\n",
        "**Total:** 5 padr√µes GoF com compara√ß√µes c√≥digo cl√°ssico vs LangExtract.\n"
      ],
      "metadata": {
        "id": "YsOLe_qNdmMN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üè≠ Factory Pattern - An√°lise Comparativa\n",
        "## LangExtract vs Padr√£o Arquitetural Cl√°ssico\n",
        "\n",
        "---\n",
        "\n",
        "## üìö **1. PADR√ÉO FACTORY CL√ÅSSICO (GoF)**\n",
        "\n",
        "### **Defini√ß√£o Te√≥rica**\n",
        "\n",
        "> **Factory Method Pattern**: Define uma interface para criar um objeto, mas deixa as subclasses decidirem qual classe instanciar. O Factory Method permite que uma classe delegue a instancia√ß√£o para subclasses.\n",
        "\n",
        "### **Estrutura UML Cl√°ssica**\n",
        "\n",
        "```\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ    Creator          ‚îÇ (Abstract)\n",
        "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
        "‚îÇ + factoryMethod()   ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ M√©todo abstrato\n",
        "‚îÇ + operation()       ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "         ‚ñ≥\n",
        "         ‚îÇ (heran√ßa)\n",
        "         ‚îÇ\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ ConcreteCreatorA    ‚îÇ\n",
        "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
        "‚îÇ + factoryMethod()   ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ Retorna ProductA\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ    Product          ‚îÇ (Interface)\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "         ‚ñ≥\n",
        "         ‚îÇ\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ   ProductA          ‚îÇ   ProductB     ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "```\n",
        "\n",
        "### **C√≥digo Exemplo Cl√°ssico**\n",
        "\n",
        "```python\n",
        "from abc import ABC, abstractmethod\n",
        "\n",
        "# 1. PRODUCT - Interface comum\n",
        "class Animal(ABC):\n",
        "    @abstractmethod\n",
        "    def speak(self) -> str:\n",
        "        pass\n",
        "\n",
        "# 2. CONCRETE PRODUCTS - Implementa√ß√µes espec√≠ficas\n",
        "class Dog(Animal):\n",
        "    def speak(self) -> str:\n",
        "        return \"Woof!\"\n",
        "\n",
        "class Cat(Animal):\n",
        "    def speak(self) -> str:\n",
        "        return \"Meow!\"\n",
        "\n",
        "# 3. CREATOR - Factory abstrata\n",
        "class AnimalFactory(ABC):\n",
        "    @abstractmethod\n",
        "    def create_animal(self) -> Animal:\n",
        "        \"\"\"Factory Method - subclasses implementam\"\"\"\n",
        "        pass\n",
        "    \n",
        "    def make_sound(self) -> str:\n",
        "        \"\"\"Opera√ß√£o que usa o factory method\"\"\"\n",
        "        animal = self.create_animal()\n",
        "        return animal.speak()\n",
        "\n",
        "# 4. CONCRETE CREATORS - Factories espec√≠ficas\n",
        "class DogFactory(AnimalFactory):\n",
        "    def create_animal(self) -> Animal:\n",
        "        return Dog()\n",
        "\n",
        "class CatFactory(AnimalFactory):\n",
        "    def create_animal(self) -> Animal:\n",
        "        return Cat()\n",
        "\n",
        "# 5. USO\n",
        "factory = DogFactory()\n",
        "print(factory.make_sound())  # Output: Woof!\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üîç **2. FACTORY NO LANGEXTRACT (factory.py)**\n",
        "\n",
        "### **Estrutura do C√≥digo Real**\n",
        "\n",
        "```python\n",
        "# ============================================\n",
        "# ARQUIVO: langextract/factory.py\n",
        "# ============================================\n",
        "\n",
        "import dataclasses\n",
        "from langextract import providers\n",
        "from langextract.providers import router\n",
        "\n",
        "@dataclasses.dataclass(slots=True, frozen=True)\n",
        "class ModelConfig:\n",
        "    \"\"\"Configura√ß√£o para criar um provider\"\"\"\n",
        "    model_id: str | None = None\n",
        "    provider: str | None = None\n",
        "    provider_kwargs: dict[str, Any] = dataclasses.field(default_factory=dict)\n",
        "\n",
        "# ============================================\n",
        "# FACTORY METHOD - Fun√ß√£o principal\n",
        "# ============================================\n",
        "def create_model(\n",
        "    config: ModelConfig,\n",
        "    examples: Sequence[Any] | None = None,\n",
        "    use_schema_constraints: bool = False,\n",
        "    fence_output: bool | None = None,\n",
        ") -> BaseLanguageModel:\n",
        "    \"\"\"\n",
        "    Factory Method que cria inst√¢ncias de providers.\n",
        "    \n",
        "    Equivale ao m√©todo abstrato factoryMethod() do padr√£o GoF.\n",
        "    \"\"\"\n",
        "    \n",
        "    # 1. Carrega providers dispon√≠veis (built-in + plugins)\n",
        "    providers.load_builtins_once()\n",
        "    providers.load_plugins_once()\n",
        "    \n",
        "    # 2. RESOLU√á√ÉO: Qual classe instanciar?\n",
        "    if config.provider:\n",
        "        # Sele√ß√£o expl√≠cita por nome\n",
        "        provider_class = router.resolve_provider(config.provider)\n",
        "    else:\n",
        "        # Sele√ß√£o autom√°tica por model_id\n",
        "        provider_class = router.resolve(config.model_id)\n",
        "    \n",
        "    # 3. PREPARA√á√ÉO: Par√¢metros com defaults\n",
        "    kwargs = _kwargs_with_environment_defaults(\n",
        "        config.model_id or config.provider or \"\",\n",
        "        config.provider_kwargs\n",
        "    )\n",
        "    \n",
        "    if config.model_id:\n",
        "        kwargs[\"model_id\"] = config.model_id\n",
        "    \n",
        "    # 4. INSTANCIA√á√ÉO: Cria o produto concreto\n",
        "    try:\n",
        "        model = provider_class(**kwargs)\n",
        "        return model\n",
        "    except (ValueError, TypeError) as e:\n",
        "        raise InferenceConfigError(\n",
        "            f\"Failed to create provider {provider_class.__name__}: {e}\"\n",
        "        ) from e\n",
        "\n",
        "# ============================================\n",
        "# HELPER: Adiciona defaults de ambiente\n",
        "# ============================================\n",
        "def _kwargs_with_environment_defaults(\n",
        "    model_id: str,\n",
        "    kwargs: dict[str, Any]\n",
        ") -> dict[str, Any]:\n",
        "    \"\"\"Adiciona API keys de vari√°veis de ambiente\"\"\"\n",
        "    resolved = dict(kwargs)\n",
        "    \n",
        "    if \"api_key\" not in resolved:\n",
        "        # Tenta buscar de GEMINI_API_KEY, OPENAI_API_KEY, etc.\n",
        "        env_vars_by_provider = {\n",
        "            \"gemini\": (\"GEMINI_API_KEY\", \"LANGEXTRACT_API_KEY\"),\n",
        "            \"gpt\": (\"OPENAI_API_KEY\", \"LANGEXTRACT_API_KEY\"),\n",
        "        }\n",
        "        \n",
        "        for provider_prefix, env_vars in env_vars_by_provider.items():\n",
        "            if provider_prefix in model_id.lower():\n",
        "                for env_var in env_vars:\n",
        "                    api_key = os.getenv(env_var)\n",
        "                    if api_key:\n",
        "                        resolved[\"api_key\"] = api_key\n",
        "                        break\n",
        "    \n",
        "    return resolved\n",
        "```\n",
        "\n",
        "### **PRODUCTS - Implementa√ß√µes concretas (providers)**\n",
        "\n",
        "```python\n",
        "# ============================================\n",
        "# ARQUIVO: langextract/providers/gemini.py\n",
        "# ============================================\n",
        "class GeminiLanguageModel(BaseLanguageModel):\n",
        "    \"\"\"Provider concreto para Gemini\"\"\"\n",
        "    \n",
        "    def __init__(self, model_id: str = 'gemini-2.5-flash', api_key: str = None, **kwargs):\n",
        "        self.model_id = model_id\n",
        "        self.api_key = api_key\n",
        "        self._client = genai.Client(api_key=api_key)\n",
        "    \n",
        "    def infer(self, batch_prompts: Sequence[str], **kwargs):\n",
        "        \"\"\"Implementa√ß√£o espec√≠fica de infer√™ncia\"\"\"\n",
        "        for prompt in batch_prompts:\n",
        "            response = self._client.models.generate_content(\n",
        "                model=self.model_id,\n",
        "                contents=prompt\n",
        "            )\n",
        "            yield [ScoredOutput(score=1.0, output=response.text)]\n",
        "\n",
        "# ============================================\n",
        "# ARQUIVO: langextract/providers/openai.py\n",
        "# ============================================\n",
        "class OpenAILanguageModel(BaseLanguageModel):\n",
        "    \"\"\"Provider concreto para OpenAI\"\"\"\n",
        "    \n",
        "    def __init__(self, model_id: str = 'gpt-4o', api_key: str = None, **kwargs):\n",
        "        self.model_id = model_id\n",
        "        self.api_key = api_key\n",
        "        self._client = openai.OpenAI(api_key=api_key)\n",
        "    \n",
        "    def infer(self, batch_prompts: Sequence[str], **kwargs):\n",
        "        \"\"\"Implementa√ß√£o espec√≠fica de infer√™ncia\"\"\"\n",
        "        for prompt in batch_prompts:\n",
        "            response = self._client.chat.completions.create(\n",
        "                model=self.model_id,\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "            )\n",
        "            yield [ScoredOutput(score=1.0, output=response.choices[0].message.content)]\n",
        "```\n",
        "\n",
        "### **INTERFACE COMUM (Product)**\n",
        "\n",
        "```python\n",
        "# ============================================\n",
        "# ARQUIVO: langextract/core/base_model.py\n",
        "# ============================================\n",
        "class BaseLanguageModel(ABC):\n",
        "    \"\"\"Interface comum para todos os providers\"\"\"\n",
        "    \n",
        "    @abstractmethod\n",
        "    def infer(self, batch_prompts: Sequence[str], **kwargs) -> Iterator[Sequence[ScoredOutput]]:\n",
        "        \"\"\"M√©todo que todo provider deve implementar\"\"\"\n",
        "        pass\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üìä **3. COMPARA√á√ÉO LADO A LADO**\n",
        "\n",
        "### **Tabela Comparativa**\n",
        "\n",
        "| Aspecto | Factory Cl√°ssico (GoF) | LangExtract Factory |\n",
        "|---------|------------------------|---------------------|\n",
        "| **Factory Method** | `create_animal()` (abstrato) | `create_model()` (fun√ß√£o) |\n",
        "| **Creators** | `DogFactory`, `CatFactory` | N√£o h√° classes creator separadas |\n",
        "| **Products** | `Dog`, `Cat` | `GeminiLanguageModel`, `OpenAILanguageModel` |\n",
        "| **Interface Product** | `Animal` | `BaseLanguageModel` |\n",
        "| **Resolu√ß√£o** | Polimorfismo (qual creator?) | Router + Registry (qual provider?) |\n",
        "| **Configura√ß√£o** | Hardcoded na factory | `ModelConfig` dataclass |\n",
        "| **Defaults** | N√£o tem | `_kwargs_with_environment_defaults()` |\n",
        "| **Extensibilidade** | Criar nova subclasse Creator | Plugin system (entry points) |\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ **4. MAPEAMENTO CONCEITUAL**\n",
        "\n",
        "### **Elementos do Padr√£o GoF ‚Üí LangExtract**\n",
        "\n",
        "```\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ  PADR√ÉO GoF              ‚Üí    LANGEXTRACT                   ‚îÇ\n",
        "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
        "‚îÇ  Creator (abstract)      ‚Üí    N√£o existe (fun√ß√£o direta)    ‚îÇ\n",
        "‚îÇ  factoryMethod()         ‚Üí    create_model()                ‚îÇ\n",
        "‚îÇ  ConcreteCreator         ‚Üí    N√£o existe (resolvido pelo    ‚îÇ\n",
        "‚îÇ                               Router)                        ‚îÇ\n",
        "‚îÇ  Product (interface)     ‚Üí    BaseLanguageModel             ‚îÇ\n",
        "‚îÇ  ConcreteProductA        ‚Üí    GeminiLanguageModel           ‚îÇ\n",
        "‚îÇ  ConcreteProductB        ‚Üí    OpenAILanguageModel           ‚îÇ\n",
        "‚îÇ  ConcreteProductC        ‚Üí    OllamaLanguageModel           ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "```\n",
        "\n",
        "### **Fluxo de Decis√£o**\n",
        "\n",
        "```\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ Cliente chama:      ‚îÇ\n",
        "‚îÇ create_model()      ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "           ‚îÇ\n",
        "           ‚ñº\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ ModelConfig         ‚îÇ\n",
        "‚îÇ - model_id          ‚îÇ ‚îÄ‚îÄ‚îê\n",
        "‚îÇ - provider          ‚îÇ   ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ\n",
        "                          ‚îÇ\n",
        "                          ‚ñº\n",
        "                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "                 ‚îÇ Router.resolve()‚îÇ\n",
        "                 ‚îÇ (Registry)      ‚îÇ\n",
        "                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                          ‚îÇ\n",
        "        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "        ‚ñº                 ‚ñº                 ‚ñº\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ Gemini       ‚îÇ  ‚îÇ OpenAI       ‚îÇ  ‚îÇ Ollama       ‚îÇ\n",
        "‚îÇ LanguageModel‚îÇ  ‚îÇ LanguageModel‚îÇ  ‚îÇ LanguageModel‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üí° **5. VARIA√á√ïES DO PADR√ÉO**\n",
        "\n",
        "### **A) Simple Factory (o que LangExtract usa)**\n",
        "\n",
        "```python\n",
        "# ‚ùå N√ÉO TEM hierarquia de Creators\n",
        "# ‚úÖ TEM fun√ß√£o factory simples\n",
        "\n",
        "def create_model(config: ModelConfig) -> BaseLanguageModel:\n",
        "    # Decis√£o baseada em config\n",
        "    if config.provider == \"gemini\":\n",
        "        return GeminiLanguageModel(...)\n",
        "    elif config.provider == \"openai\":\n",
        "        return OpenAILanguageModel(...)\n",
        "    # ...\n",
        "```\n",
        "\n",
        "**Caracter√≠stica:** Uma √∫nica fun√ß√£o decide qual classe instanciar.\n",
        "\n",
        "### **B) Factory Method (GoF cl√°ssico)**\n",
        "\n",
        "```python\n",
        "# ‚úÖ TEM hierarquia de Creators\n",
        "# ‚úÖ TEM m√©todo abstrato\n",
        "\n",
        "class ModelFactory(ABC):\n",
        "    @abstractmethod\n",
        "    def create_model(self) -> BaseLanguageModel:\n",
        "        pass\n",
        "\n",
        "class GeminiFactory(ModelFactory):\n",
        "    def create_model(self) -> BaseLanguageModel:\n",
        "        return GeminiLanguageModel(...)\n",
        "\n",
        "class OpenAIFactory(ModelFactory):\n",
        "    def create_model(self) -> BaseLanguageModel:\n",
        "        return OpenAILanguageModel(...)\n",
        "```\n",
        "\n",
        "**Caracter√≠stica:** Hierarquia de classes factory.\n",
        "\n",
        "### **C) Abstract Factory (m√∫ltiplas fam√≠lias)**\n",
        "\n",
        "```python\n",
        "class LLMProviderFactory(ABC):\n",
        "    @abstractmethod\n",
        "    def create_language_model(self) -> BaseLanguageModel:\n",
        "        pass\n",
        "    \n",
        "    @abstractmethod\n",
        "    def create_embedder(self) -> BaseEmbedder:\n",
        "        pass\n",
        "    \n",
        "    @abstractmethod\n",
        "    def create_tokenizer(self) -> BaseTokenizer:\n",
        "        pass\n",
        "\n",
        "class GeminiProviderFactory(LLMProviderFactory):\n",
        "    # Cria fam√≠lia completa de produtos Gemini\n",
        "    ...\n",
        "```\n",
        "\n",
        "**Caracter√≠stica:** Cria fam√≠lias de produtos relacionados.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ **6. VEREDITO: QUAL VARIA√á√ÉO √â USADA?**\n",
        "\n",
        "### **LangExtract implementa: Simple Factory + Registry Pattern**\n",
        "\n",
        "```\n",
        "Simple Factory:\n",
        "    ‚úÖ Fun√ß√£o create_model() centralizada\n",
        "    ‚úÖ N√£o h√° hierarquia de creators\n",
        "    ‚úÖ Decis√£o interna sobre qual classe criar\n",
        "\n",
        "Registry Pattern (adicional):\n",
        "    ‚úÖ Router mapeia model_id ‚Üí provider_class\n",
        "    ‚úÖ Permite registro din√¢mico de providers\n",
        "    ‚úÖ Extens√≠vel via plugins\n",
        "```\n",
        "\n",
        "### **Por que n√£o √© Factory Method puro?**\n",
        "\n",
        "1. **N√£o h√° classes Creator**: Apenas uma fun√ß√£o `create_model()`\n",
        "2. **N√£o usa polimorfismo de Creator**: Usa Router para resolver\n",
        "3. **Mais simples**: Adequado para o caso de uso\n",
        "\n",
        "### **Por que n√£o √© Abstract Factory?**\n",
        "\n",
        "1. **N√£o cria fam√≠lias de produtos**: S√≥ cria `BaseLanguageModel`\n",
        "2. **N√£o h√° m√∫ltiplos m√©todos factory relacionados**\n",
        "\n",
        "---\n",
        "\n",
        "## üìà **7. VANTAGENS DA IMPLEMENTA√á√ÉO DO LANGEXTRACT**\n",
        "\n",
        "| Vantagem | Descri√ß√£o |\n",
        "|----------|-----------|\n",
        "| **Simplicidade** | Uma fun√ß√£o, n√£o hierarquia de classes |\n",
        "| **Flexibilidade** | ModelConfig aceita model_id OU provider expl√≠cito |\n",
        "| **Extensibilidade** | Plugin system permite adicionar providers sem modificar c√≥digo |\n",
        "| **Defaults inteligentes** | API keys de vari√°veis de ambiente |\n",
        "| **Separa√ß√£o de responsabilidades** | Router cuida da resolu√ß√£o, Factory cuida da instancia√ß√£o |\n",
        "| **Type Safety** | Retorna tipo abstrato `BaseLanguageModel` |\n",
        "\n",
        "---\n",
        "\n",
        "## üéì **8. EXEMPLO DE USO COMPARADO**\n",
        "\n",
        "### **Factory Cl√°ssico**\n",
        "\n",
        "```python\n",
        "# Cliente precisa saber qual factory usar\n",
        "factory = DogFactory()  # ‚Üê Cliente decide\n",
        "animal = factory.create_animal()\n",
        "print(animal.speak())\n",
        "```\n",
        "\n",
        "### **LangExtract Factory**\n",
        "\n",
        "```python\n",
        "# Cliente s√≥ passa configura√ß√£o, factory decide\n",
        "config = ModelConfig(model_id=\"gemini-2.5-flash\")\n",
        "model = create_model(config)  # ‚Üê Factory decide internamente\n",
        "result = model.infer([\"Hello\"])\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üîß **9. C√ìDIGO COMPLETO DE COMPARA√á√ÉO**\n",
        "\n",
        "### **Factory Cl√°ssico GoF - Vers√£o Completa**\n",
        "\n",
        "```python\n",
        "from abc import ABC, abstractmethod\n",
        "\n",
        "# ========== PRODUCTS ==========\n",
        "class Vehicle(ABC):\n",
        "    @abstractmethod\n",
        "    def drive(self) -> str:\n",
        "        pass\n",
        "\n",
        "class Car(Vehicle):\n",
        "    def drive(self) -> str:\n",
        "        return \"Driving a car üöó\"\n",
        "\n",
        "class Truck(Vehicle):\n",
        "    def drive(self) -> str:\n",
        "        return \"Driving a truck üöö\"\n",
        "\n",
        "# ========== CREATORS ==========\n",
        "class VehicleFactory(ABC):\n",
        "    @abstractmethod\n",
        "    def create_vehicle(self) -> Vehicle:\n",
        "        \"\"\"Factory Method\"\"\"\n",
        "        pass\n",
        "    \n",
        "    def deliver(self) -> str:\n",
        "        \"\"\"Opera√ß√£o que usa o factory method\"\"\"\n",
        "        vehicle = self.create_vehicle()\n",
        "        return vehicle.drive()\n",
        "\n",
        "class CarFactory(VehicleFactory):\n",
        "    def create_vehicle(self) -> Vehicle:\n",
        "        return Car()\n",
        "\n",
        "class TruckFactory(VehicleFactory):\n",
        "    def create_vehicle(self) -> Vehicle:\n",
        "        return Truck()\n",
        "\n",
        "# ========== USO ==========\n",
        "def main():\n",
        "    # Cliente escolhe factory\n",
        "    factory: VehicleFactory = CarFactory()\n",
        "    print(factory.deliver())  # Driving a car üöó\n",
        "    \n",
        "    factory = TruckFactory()\n",
        "    print(factory.deliver())  # Driving a truck üöö\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "```\n",
        "\n",
        "### **LangExtract Factory - Vers√£o Simplificada**\n",
        "\n",
        "```python\n",
        "from abc import ABC, abstractmethod\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, Type\n",
        "\n",
        "# ========== PRODUCT INTERFACE ==========\n",
        "class BaseLanguageModel(ABC):\n",
        "    @abstractmethod\n",
        "    def infer(self, prompt: str) -> str:\n",
        "        pass\n",
        "\n",
        "# ========== CONCRETE PRODUCTS ==========\n",
        "class GeminiLanguageModel(BaseLanguageModel):\n",
        "    def __init__(self, model_id: str, api_key: str):\n",
        "        self.model_id = model_id\n",
        "        self.api_key = api_key\n",
        "    \n",
        "    def infer(self, prompt: str) -> str:\n",
        "        return f\"Gemini ({self.model_id}): {prompt}\"\n",
        "\n",
        "class OpenAILanguageModel(BaseLanguageModel):\n",
        "    def __init__(self, model_id: str, api_key: str):\n",
        "        self.model_id = model_id\n",
        "        self.api_key = api_key\n",
        "    \n",
        "    def infer(self, prompt: str) -> str:\n",
        "        return f\"OpenAI ({self.model_id}): {prompt}\"\n",
        "\n",
        "# ========== REGISTRY (Router) ==========\n",
        "class ProviderRegistry:\n",
        "    _providers: Dict[str, Type[BaseLanguageModel]] = {\n",
        "        \"gemini\": GeminiLanguageModel,\n",
        "        \"openai\": OpenAILanguageModel,\n",
        "    }\n",
        "    \n",
        "    @classmethod\n",
        "    def resolve(cls, model_id: str) -> Type[BaseLanguageModel]:\n",
        "        if \"gemini\" in model_id.lower():\n",
        "            return cls._providers[\"gemini\"]\n",
        "        elif \"gpt\" in model_id.lower():\n",
        "            return cls._providers[\"openai\"]\n",
        "        raise ValueError(f\"Unknown model: {model_id}\")\n",
        "\n",
        "# ========== CONFIGURATION ==========\n",
        "@dataclass\n",
        "class ModelConfig:\n",
        "    model_id: str\n",
        "    api_key: str\n",
        "\n",
        "# ========== SIMPLE FACTORY ==========\n",
        "def create_model(config: ModelConfig) -> BaseLanguageModel:\n",
        "    \"\"\"Factory function - Simple Factory Pattern\"\"\"\n",
        "    \n",
        "    # 1. Resolve qual classe usar\n",
        "    provider_class = ProviderRegistry.resolve(config.model_id)\n",
        "    \n",
        "    # 2. Instancia com par√¢metros\n",
        "    model = provider_class(\n",
        "        model_id=config.model_id,\n",
        "        api_key=config.api_key\n",
        "    )\n",
        "    \n",
        "    return model\n",
        "\n",
        "# ========== USO ==========\n",
        "def main():\n",
        "    # Cliente n√£o sabe qual provider ser√° usado\n",
        "    config = ModelConfig(\n",
        "        model_id=\"gemini-2.5-flash\",\n",
        "        api_key=\"fake-key\"\n",
        "    )\n",
        "    \n",
        "    model = create_model(config)  # ‚Üê Factory decide\n",
        "    print(model.infer(\"Hello!\"))  # Gemini (gemini-2.5-flash): Hello!\n",
        "    \n",
        "    # Trocar provider √© transparente\n",
        "    config = ModelConfig(\n",
        "        model_id=\"gpt-4o\",\n",
        "        api_key=\"fake-key\"\n",
        "    )\n",
        "    \n",
        "    model = create_model(config)\n",
        "    print(model.infer(\"Hello!\"))  # OpenAI (gpt-4o): Hello!\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "l9wDhVZkdwRo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîÑ Iterator Pattern - An√°lise LangExtract\n",
        "## Compara√ß√£o: chunking.py vs Padr√£o GoF\n",
        "\n",
        "---\n",
        "\n",
        "## üìö **1. PADR√ÉO ITERATOR (GoF) - RESUMO**\n",
        "\n",
        "### **Defini√ß√£o**\n",
        "> Fornece uma maneira de acessar sequencialmente elementos de uma cole√ß√£o sem expor sua representa√ß√£o interna.\n",
        "\n",
        "### **Estrutura Cl√°ssica**\n",
        "\n",
        "```python\n",
        "from abc import ABC, abstractmethod\n",
        "\n",
        "# Iterator Interface\n",
        "class Iterator(ABC):\n",
        "    @abstractmethod\n",
        "    def __next__(self):\n",
        "        pass\n",
        "    \n",
        "    @abstractmethod\n",
        "    def has_next(self) -> bool:\n",
        "        pass\n",
        "\n",
        "# Aggregate Interface\n",
        "class Iterable(ABC):\n",
        "    @abstractmethod\n",
        "    def __iter__(self) -> Iterator:\n",
        "        pass\n",
        "\n",
        "# Concrete Iterator\n",
        "class ListIterator(Iterator):\n",
        "    def __init__(self, collection: list):\n",
        "        self._collection = collection\n",
        "        self._position = 0\n",
        "    \n",
        "    def __next__(self):\n",
        "        if self.has_next():\n",
        "            item = self._collection[self._position]\n",
        "            self._position += 1\n",
        "            return item\n",
        "        raise StopIteration\n",
        "    \n",
        "    def has_next(self) -> bool:\n",
        "        return self._position < len(self._collection)\n",
        "\n",
        "# Concrete Aggregate\n",
        "class MyList(Iterable):\n",
        "    def __init__(self):\n",
        "        self._items = []\n",
        "    \n",
        "    def add(self, item):\n",
        "        self._items.append(item)\n",
        "    \n",
        "    def __iter__(self) -> Iterator:\n",
        "        return ListIterator(self._items)\n",
        "\n",
        "# USO\n",
        "my_list = MyList()\n",
        "my_list.add(\"A\")\n",
        "my_list.add(\"B\")\n",
        "\n",
        "for item in my_list:  # Python chama __iter__() e __next__()\n",
        "    print(item)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üîç **2. ITERATOR NO LANGEXTRACT (chunking.py)**\n",
        "\n",
        "### **A) ChunkIterator - Divide documentos em chunks**\n",
        "\n",
        "```python\n",
        "# ============================================\n",
        "# ARQUIVO: langextract/chunking.py\n",
        "# ============================================\n",
        "\n",
        "class ChunkIterator:\n",
        "    \"\"\"Itera chunks de texto tokenizado respeitando max_char_buffer\"\"\"\n",
        "    \n",
        "    def __init__(\n",
        "        self,\n",
        "        text: str | TokenizedText,\n",
        "        max_char_buffer: int,\n",
        "        document: Document | None = None,\n",
        "    ):\n",
        "        if isinstance(text, str):\n",
        "            text = TokenizedText(text=text)\n",
        "        \n",
        "        self.tokenized_text = text\n",
        "        self.max_char_buffer = max_char_buffer\n",
        "        self.sentence_iter = SentenceIterator(self.tokenized_text)\n",
        "        self.broken_sentence = False\n",
        "        self.document = document if document else Document(text=text.text)\n",
        "    \n",
        "    def __iter__(self) -> Iterator[TextChunk]:\n",
        "        \"\"\"Protocolo Iterator: retorna self\"\"\"\n",
        "        return self\n",
        "    \n",
        "    def __next__(self) -> TextChunk:\n",
        "        \"\"\"Protocolo Iterator: retorna pr√≥ximo chunk\"\"\"\n",
        "        sentence = next(self.sentence_iter)  # Pode lan√ßar StopIteration\n",
        "        \n",
        "        # Inicializa chunk com primeiro token\n",
        "        curr_chunk = create_token_interval(\n",
        "            sentence.start_index,\n",
        "            sentence.start_index + 1\n",
        "        )\n",
        "        \n",
        "        # Se token excede buffer, retorna s√≥ ele\n",
        "        if self._tokens_exceed_buffer(curr_chunk):\n",
        "            self.sentence_iter = SentenceIterator(\n",
        "                self.tokenized_text,\n",
        "                curr_token_pos=sentence.start_index + 1\n",
        "            )\n",
        "            self.broken_sentence = True\n",
        "            return TextChunk(token_interval=curr_chunk, document=self.document)\n",
        "        \n",
        "        # Adiciona tokens at√© atingir max_char_buffer\n",
        "        start_of_new_line = -1\n",
        "        for token_index in range(curr_chunk.start_index, sentence.end_index):\n",
        "            if self.tokenized_text.tokens[token_index].first_token_after_newline:\n",
        "                start_of_new_line = token_index\n",
        "            \n",
        "            test_chunk = create_token_interval(\n",
        "                curr_chunk.start_index,\n",
        "                token_index + 1\n",
        "            )\n",
        "            \n",
        "            if self._tokens_exceed_buffer(test_chunk):\n",
        "                # Quebra em newline se poss√≠vel\n",
        "                if start_of_new_line > curr_chunk.start_index:\n",
        "                    curr_chunk = create_token_interval(\n",
        "                        curr_chunk.start_index,\n",
        "                        start_of_new_line\n",
        "                    )\n",
        "                \n",
        "                self.sentence_iter = SentenceIterator(\n",
        "                    self.tokenized_text,\n",
        "                    curr_token_pos=curr_chunk.end_index\n",
        "                )\n",
        "                self.broken_sentence = True\n",
        "                return TextChunk(token_interval=curr_chunk, document=self.document)\n",
        "            else:\n",
        "                curr_chunk = test_chunk\n",
        "        \n",
        "        # Tenta adicionar senten√ßas completas se couber\n",
        "        if not self.broken_sentence:\n",
        "            for sentence in self.sentence_iter:\n",
        "                test_chunk = create_token_interval(\n",
        "                    curr_chunk.start_index,\n",
        "                    sentence.end_index\n",
        "                )\n",
        "                \n",
        "                if self._tokens_exceed_buffer(test_chunk):\n",
        "                    self.sentence_iter = SentenceIterator(\n",
        "                        self.tokenized_text,\n",
        "                        curr_token_pos=curr_chunk.end_index\n",
        "                    )\n",
        "                    return TextChunk(token_interval=curr_chunk, document=self.document)\n",
        "                else:\n",
        "                    curr_chunk = test_chunk\n",
        "        \n",
        "        self.broken_sentence = False\n",
        "        return TextChunk(token_interval=curr_chunk, document=self.document)\n",
        "    \n",
        "    def _tokens_exceed_buffer(self, token_interval: TokenInterval) -> bool:\n",
        "        \"\"\"Verifica se intervalo excede buffer m√°ximo\"\"\"\n",
        "        char_interval = get_char_interval(self.tokenized_text, token_interval)\n",
        "        return (char_interval.end_pos - char_interval.start_pos) > self.max_char_buffer\n",
        "```\n",
        "\n",
        "### **B) SentenceIterator - Itera por senten√ßas**\n",
        "\n",
        "```python\n",
        "class SentenceIterator:\n",
        "    \"\"\"Itera atrav√©s de senten√ßas em texto tokenizado\"\"\"\n",
        "    \n",
        "    def __init__(\n",
        "        self,\n",
        "        tokenized_text: TokenizedText,\n",
        "        curr_token_pos: int = 0,\n",
        "    ):\n",
        "        self.tokenized_text = tokenized_text\n",
        "        self.token_len = len(tokenized_text.tokens)\n",
        "        \n",
        "        if curr_token_pos < 0 or curr_token_pos > self.token_len:\n",
        "            raise IndexError(f\"Invalid token position: {curr_token_pos}\")\n",
        "        \n",
        "        self.curr_token_pos = curr_token_pos\n",
        "    \n",
        "    def __iter__(self) -> Iterator[TokenInterval]:\n",
        "        \"\"\"Protocolo Iterator: retorna self\"\"\"\n",
        "        return self\n",
        "    \n",
        "    def __next__(self) -> TokenInterval:\n",
        "        \"\"\"Protocolo Iterator: retorna pr√≥xima senten√ßa\"\"\"\n",
        "        if self.curr_token_pos == self.token_len:\n",
        "            raise StopIteration\n",
        "        \n",
        "        # Localiza range da senten√ßa contendo token atual\n",
        "        sentence_range = tokenizer.find_sentence_range(\n",
        "            self.tokenized_text.text,\n",
        "            self.tokenized_text.tokens,\n",
        "            self.curr_token_pos,\n",
        "        )\n",
        "        \n",
        "        # Ajusta para come√ßar da posi√ß√£o atual\n",
        "        sentence_range = create_token_interval(\n",
        "            self.curr_token_pos,\n",
        "            sentence_range.end_index\n",
        "        )\n",
        "        \n",
        "        self.curr_token_pos = sentence_range.end_index\n",
        "        return sentence_range\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üìä **3. COMPARA√á√ÉO DIRETA**\n",
        "\n",
        "| Aspecto | Iterator Cl√°ssico | LangExtract ChunkIterator |\n",
        "|---------|-------------------|---------------------------|\n",
        "| **`__iter__()`** | ‚úÖ Retorna Iterator | ‚úÖ `return self` |\n",
        "| **`__next__()`** | ‚úÖ Retorna pr√≥ximo item | ‚úÖ Retorna `TextChunk` |\n",
        "| **`StopIteration`** | ‚úÖ Lan√ßa quando acabar | ‚úÖ Delegado para `SentenceIterator` |\n",
        "| **Estado interno** | `_position` (√≠ndice) | `sentence_iter`, `broken_sentence` |\n",
        "| **Lazy evaluation** | ‚úÖ SIM | ‚úÖ SIM (processa sob demanda) |\n",
        "| **Itera√ß√£o aninhada** | ‚ùå N√£o | ‚úÖ SIM (`ChunkIterator` usa `SentenceIterator`) |\n",
        "| **L√≥gica complexa** | ‚ùå Simples (index++) | ‚úÖ Complexa (buffer, newlines, senten√ßas) |\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ **4. MAPEAMENTO CONCEITUAL**\n",
        "\n",
        "```\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ  PADR√ÉO GoF          ‚Üí    LANGEXTRACT                    ‚îÇ\n",
        "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
        "‚îÇ  Iterator            ‚Üí    ChunkIterator                  ‚îÇ\n",
        "‚îÇ  __iter__()          ‚Üí    return self                    ‚îÇ\n",
        "‚îÇ  __next__()          ‚Üí    Retorna TextChunk              ‚îÇ\n",
        "‚îÇ  has_next()          ‚Üí    Impl√≠cito (StopIteration)      ‚îÇ\n",
        "‚îÇ  Aggregate           ‚Üí    TokenizedText (cole√ß√£o)        ‚îÇ\n",
        "‚îÇ  Item                ‚Üí    TextChunk (elemento)           ‚îÇ\n",
        "‚îÇ  Estado (_position)  ‚Üí    sentence_iter + broken_sentence‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üí° **5. DIFEREN√áAS PRINCIPAIS**\n",
        "\n",
        "### **A) Iterator Cl√°ssico: Simples**\n",
        "```python\n",
        "class SimpleIterator:\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "        self.index = 0  # ‚Üê Estado simples\n",
        "    \n",
        "    def __next__(self):\n",
        "        if self.index >= len(self.data):\n",
        "            raise StopIteration\n",
        "        item = self.data[self.index]\n",
        "        self.index += 1  # ‚Üê Incremento simples\n",
        "        return item\n",
        "```\n",
        "\n",
        "### **B) ChunkIterator: Complexo**\n",
        "```python\n",
        "class ChunkIterator:\n",
        "    def __init__(self, text, max_char_buffer):\n",
        "        self.tokenized_text = text\n",
        "        self.max_char_buffer = max_char_buffer\n",
        "        self.sentence_iter = SentenceIterator(...)  # ‚Üê Iterator aninhado\n",
        "        self.broken_sentence = False  # ‚Üê Estado adicional\n",
        "    \n",
        "    def __next__(self):\n",
        "        # 1. Pega senten√ßa\n",
        "        sentence = next(self.sentence_iter)\n",
        "        \n",
        "        # 2. L√≥gica complexa: buffer, newlines, tokens\n",
        "        # ... 50+ linhas de l√≥gica\n",
        "        \n",
        "        # 3. Retorna chunk otimizado\n",
        "        return TextChunk(...)\n",
        "```\n",
        "\n",
        "**Por qu√™?**\n",
        "- Precisa respeitar limite de caracteres (`max_char_buffer`)\n",
        "- Prefere quebrar em newlines quando poss√≠vel\n",
        "- Agrupa senten√ßas completas se couberem no buffer\n",
        "- Trata tokens gigantes que excedem buffer\n",
        "\n",
        "---\n",
        "\n",
        "## üîß **6. EXEMPLO DE USO COMPARADO**\n",
        "\n",
        "### **Iterator Cl√°ssico**\n",
        "\n",
        "```python\n",
        "# Cria cole√ß√£o iter√°vel\n",
        "numbers = MyList()\n",
        "numbers.add(1)\n",
        "numbers.add(2)\n",
        "numbers.add(3)\n",
        "\n",
        "# Itera\n",
        "for num in numbers:\n",
        "    print(num)\n",
        "\n",
        "# Output: 1, 2, 3\n",
        "```\n",
        "\n",
        "### **ChunkIterator no LangExtract**\n",
        "\n",
        "```python\n",
        "# Texto longo\n",
        "text = \"\"\"\n",
        "This is a very long document that needs to be split into chunks\n",
        "for processing by an LLM with limited context window.\n",
        "Each chunk should be around 200 characters maximum.\n",
        "\"\"\"\n",
        "\n",
        "# Cria iterator\n",
        "chunk_iter = ChunkIterator(\n",
        "    text=text,\n",
        "    max_char_buffer=200,\n",
        "    document=Document(text=text)\n",
        ")\n",
        "\n",
        "# Itera por chunks\n",
        "for chunk in chunk_iter:\n",
        "    print(f\"Chunk: {chunk.chunk_text[:50]}...\")\n",
        "    print(f\"Size: {len(chunk.chunk_text)} chars\\n\")\n",
        "\n",
        "# Output:\n",
        "# Chunk: This is a very long document that needs to be ...\n",
        "# Size: 197 chars\n",
        "#\n",
        "# Chunk: for processing by an LLM with limited context...\n",
        "# Size: 186 chars\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ **7. CHECKLIST DE VERIFICA√á√ÉO**\n",
        "\n",
        "| Caracter√≠stica do Iterator Pattern | ChunkIterator | SentenceIterator |\n",
        "|-------------------------------------|---------------|------------------|\n",
        "| ‚úÖ Implementa `__iter__()` | ‚úÖ SIM | ‚úÖ SIM |\n",
        "| ‚úÖ Implementa `__next__()` | ‚úÖ SIM | ‚úÖ SIM |\n",
        "| ‚úÖ Lan√ßa `StopIteration` | ‚úÖ SIM | ‚úÖ SIM |\n",
        "| ‚úÖ Mant√©m estado interno | ‚úÖ SIM | ‚úÖ SIM |\n",
        "| ‚úÖ Lazy evaluation | ‚úÖ SIM | ‚úÖ SIM |\n",
        "| ‚úÖ Funciona com `for` loop | ‚úÖ SIM | ‚úÖ SIM |\n",
        "| ‚úÖ Esconde representa√ß√£o interna | ‚úÖ SIM | ‚úÖ SIM |\n",
        "\n",
        "---\n",
        "\n",
        "## üìà **8. VANTAGENS DA IMPLEMENTA√á√ÉO**\n",
        "\n",
        "| Vantagem | Descri√ß√£o |\n",
        "|----------|-----------|\n",
        "| **Mem√≥ria eficiente** | N√£o carrega documento inteiro na mem√≥ria |\n",
        "| **Streaming** | Processa chunks sob demanda |\n",
        "| **Flex√≠vel** | L√≥gica complexa de chunking encapsulada |\n",
        "| **Pythonic** | Usa protocolo nativo (`__iter__`, `__next__`) |\n",
        "| **Composi√ß√£o** | `ChunkIterator` usa `SentenceIterator` internamente |\n",
        "| **Reutiliz√°vel** | Pode iterar m√∫ltiplas vezes criando novo iterator |\n",
        "\n",
        "---\n",
        "\n",
        "## üéì **9. C√ìDIGO EXECUT√ÅVEL COMPLETO**\n",
        "\n",
        "### **A) Iterator Cl√°ssico (Simples)**\n",
        "\n",
        "```python\n",
        "from abc import ABC, abstractmethod\n",
        "\n",
        "class Iterator(ABC):\n",
        "    @abstractmethod\n",
        "    def __next__(self):\n",
        "        pass\n",
        "\n",
        "class BookShelf:\n",
        "    \"\"\"Aggregate: Cole√ß√£o de livros\"\"\"\n",
        "    def __init__(self):\n",
        "        self._books = []\n",
        "    \n",
        "    def add(self, book: str):\n",
        "        self._books.append(book)\n",
        "    \n",
        "    def __iter__(self):\n",
        "        \"\"\"Retorna iterator\"\"\"\n",
        "        return BookIterator(self._books)\n",
        "\n",
        "class BookIterator:\n",
        "    \"\"\"Iterator: Percorre livros\"\"\"\n",
        "    def __init__(self, books: list):\n",
        "        self._books = books\n",
        "        self._index = 0\n",
        "    \n",
        "    def __iter__(self):\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        if self._index >= len(self._books):\n",
        "            raise StopIteration\n",
        "        \n",
        "        book = self._books[self._index]\n",
        "        self._index += 1\n",
        "        return book\n",
        "\n",
        "# USO\n",
        "shelf = BookShelf()\n",
        "shelf.add(\"Python Design Patterns\")\n",
        "shelf.add(\"Clean Code\")\n",
        "shelf.add(\"Refactoring\")\n",
        "\n",
        "for book in shelf:\n",
        "    print(f\"üìö {book}\")\n",
        "```\n",
        "\n",
        "### **B) ChunkIterator (Simplificado)**\n",
        "\n",
        "```python\n",
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class Chunk:\n",
        "    text: str\n",
        "    start: int\n",
        "    end: int\n",
        "\n",
        "class TextChunker:\n",
        "    \"\"\"Iterator que divide texto em chunks de tamanho fixo\"\"\"\n",
        "    \n",
        "    def __init__(self, text: str, chunk_size: int):\n",
        "        self.text = text\n",
        "        self.chunk_size = chunk_size\n",
        "        self.position = 0\n",
        "    \n",
        "    def __iter__(self):\n",
        "        return self\n",
        "    \n",
        "    def __next__(self) -> Chunk:\n",
        "        if self.position >= len(self.text):\n",
        "            raise StopIteration\n",
        "        \n",
        "        start = self.position\n",
        "        end = min(self.position + self.chunk_size, len(self.text))\n",
        "        \n",
        "        # Tenta quebrar em espa√ßo para n√£o partir palavras\n",
        "        if end < len(self.text) and self.text[end] != ' ':\n",
        "            # Procura √∫ltimo espa√ßo antes do fim\n",
        "            last_space = self.text.rfind(' ', start, end)\n",
        "            if last_space > start:\n",
        "                end = last_space + 1\n",
        "        \n",
        "        chunk_text = self.text[start:end]\n",
        "        self.position = end\n",
        "        \n",
        "        return Chunk(text=chunk_text, start=start, end=end)\n",
        "\n",
        "# USO\n",
        "text = \"The quick brown fox jumps over the lazy dog. Pack my box with five dozen liquor jugs.\"\n",
        "chunker = TextChunker(text, chunk_size=30)\n",
        "\n",
        "for i, chunk in enumerate(chunker, 1):\n",
        "    print(f\"Chunk {i}: '{chunk.text}' [{chunk.start}:{chunk.end}]\")\n",
        "\n",
        "# Output:\n",
        "# Chunk 1: 'The quick brown fox jumps ' [0:26]\n",
        "# Chunk 2: 'over the lazy dog. Pack my ' [26:53]\n",
        "# Chunk 3: 'box with five dozen liquor ' [53:80]\n",
        "# Chunk 4: 'jugs.' [80:85]\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üìù **10. CONCLUS√ÉO**\n",
        "\n",
        "### **‚úÖ √â Iterator Pattern? SIM!**\n",
        "\n",
        "**ChunkIterator e SentenceIterator implementam PERFEITAMENTE o padr√£o Iterator:**\n",
        "\n",
        "1. ‚úÖ Protocolo Python (`__iter__`, `__next__`, `StopIteration`)\n",
        "2. ‚úÖ Acesso sequencial sem expor representa√ß√£o interna\n",
        "3. ‚úÖ Lazy evaluation (processa sob demanda)\n",
        "4. ‚úÖ Estado interno gerenciado pelo iterator\n",
        "5. ‚úÖ Permite m√∫ltiplas itera√ß√µes independentes\n",
        "\n",
        "### **Diferencial do LangExtract:**\n",
        "\n",
        "- **L√≥gica de neg√≥cio complexa** embutida no iterator\n",
        "- **Iterators compostos** (`ChunkIterator` usa `SentenceIterator`)\n",
        "- **Otimiza√ß√µes** (newlines, buffer, senten√ßas completas)\n",
        "- **Aplica√ß√£o real** para processamento de LLMs\n",
        "\n",
        "### **Classifica√ß√£o:**\n",
        "üèÜ **Iterator Pattern (GoF) - Implementa√ß√£o Avan√ßada com L√≥gica de Dom√≠nio**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "c-LNsXU6eYWM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üé≠ Facade Pattern - An√°lise LangExtract\n",
        "## Compara√ß√£o: extraction.py vs Padr√£o GoF\n",
        "\n",
        "---\n",
        "\n",
        "## üìö **1. PADR√ÉO FACADE (GoF) - RESUMO**\n",
        "\n",
        "### **Defini√ß√£o**\n",
        "> Fornece uma interface unificada para um conjunto de interfaces em um subsistema. Facade define uma interface de n√≠vel mais alto que torna o subsistema mais f√°cil de usar.\n",
        "\n",
        "### **Estrutura Cl√°ssica**\n",
        "\n",
        "```python\n",
        "# ============================================\n",
        "# SUBSISTEMAS COMPLEXOS (m√∫ltiplas classes)\n",
        "# ============================================\n",
        "\n",
        "class SubsystemA:\n",
        "    def operation_a1(self):\n",
        "        return \"SubsystemA: opera√ß√£o A1\"\n",
        "    \n",
        "    def operation_a2(self):\n",
        "        return \"SubsystemA: opera√ß√£o A2\"\n",
        "\n",
        "class SubsystemB:\n",
        "    def operation_b1(self):\n",
        "        return \"SubsystemB: opera√ß√£o B1\"\n",
        "    \n",
        "    def operation_b2(self):\n",
        "        return \"SubsystemB: opera√ß√£o B2\"\n",
        "\n",
        "class SubsystemC:\n",
        "    def operation_c1(self):\n",
        "        return \"SubsystemC: opera√ß√£o C1\"\n",
        "\n",
        "# ============================================\n",
        "# FACADE - Interface simplificada\n",
        "# ============================================\n",
        "\n",
        "class Facade:\n",
        "    \"\"\"Esconde a complexidade dos subsistemas\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self._subsystem_a = SubsystemA()\n",
        "        self._subsystem_b = SubsystemB()\n",
        "        self._subsystem_c = SubsystemC()\n",
        "    \n",
        "    def simple_operation(self):\n",
        "        \"\"\"Uma chamada simples que coordena subsistemas\"\"\"\n",
        "        results = []\n",
        "        results.append(self._subsystem_a.operation_a1())\n",
        "        results.append(self._subsystem_b.operation_b1())\n",
        "        results.append(self._subsystem_c.operation_c1())\n",
        "        return \"\\n\".join(results)\n",
        "\n",
        "# ============================================\n",
        "# USO - Cliente usa facade, n√£o subsistemas\n",
        "# ============================================\n",
        "\n",
        "# ‚ùå SEM Facade (cliente lida com complexidade):\n",
        "subsystem_a = SubsystemA()\n",
        "subsystem_b = SubsystemB()\n",
        "subsystem_c = SubsystemC()\n",
        "result1 = subsystem_a.operation_a1()\n",
        "result2 = subsystem_b.operation_b1()\n",
        "result3 = subsystem_c.operation_c1()\n",
        "\n",
        "# ‚úÖ COM Facade (cliente usa interface simples):\n",
        "facade = Facade()\n",
        "result = facade.simple_operation()  # ‚Üê Tudo em uma chamada!\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üîç **2. FACADE NO LANGEXTRACT (extraction.py)**\n",
        "\n",
        "### **A) Fun√ß√£o `extract()` - A Facade Principal**\n",
        "\n",
        "```python\n",
        "# ============================================\n",
        "# ARQUIVO: langextract/extraction.py\n",
        "# ============================================\n",
        "\n",
        "def extract(\n",
        "    text_or_documents: Any,\n",
        "    prompt_description: str | None = None,\n",
        "    examples: Sequence[Any] | None = None,\n",
        "    model_id: str = \"gemini-2.5-flash\",\n",
        "    api_key: str | None = None,\n",
        "    # ... muitos outros par√¢metros opcionais\n",
        ") -> Any:\n",
        "    \"\"\"\n",
        "    FACADE: Interface simplificada para extra√ß√£o estruturada.\n",
        "    \n",
        "    Esconde a complexidade de:\n",
        "    - Factory (cria√ß√£o de models)\n",
        "    - Prompting (gera√ß√£o de prompts)\n",
        "    - FormatHandler (parsing JSON/YAML)\n",
        "    - Resolver (convers√£o string ‚Üí Extraction)\n",
        "    - Annotator (pipeline de extra√ß√£o)\n",
        "    - Chunking (divis√£o de documentos)\n",
        "    - Alignment (mapeamento texto ‚Üí posi√ß√µes)\n",
        "    \"\"\"\n",
        "    \n",
        "    # ============================================\n",
        "    # 1. VALIDA√á√ÉO\n",
        "    # ============================================\n",
        "    if not examples:\n",
        "        raise ValueError(\"Examples are required...\")\n",
        "    \n",
        "    if prompt_validation_level is not pv.PromptValidationLevel.OFF:\n",
        "        report = pv.validate_prompt_alignment(examples=examples, ...)\n",
        "        pv.handle_alignment_report(report, ...)\n",
        "    \n",
        "    # ============================================\n",
        "    # 2. SUBSISTEMA: DOWNLOAD (se necess√°rio)\n",
        "    # ============================================\n",
        "    if fetch_urls and isinstance(text_or_documents, str) and io.is_url(text_or_documents):\n",
        "        text_or_documents = io.download_text_from_url(text_or_documents)\n",
        "    \n",
        "    # ============================================\n",
        "    # 3. SUBSISTEMA: PROMPTING\n",
        "    # ============================================\n",
        "    prompt_template = prompting.PromptTemplateStructured(\n",
        "        description=prompt_description\n",
        "    )\n",
        "    prompt_template.examples.extend(examples)\n",
        "    \n",
        "    # ============================================\n",
        "    # 4. SUBSISTEMA: FACTORY (cria√ß√£o de model)\n",
        "    # ============================================\n",
        "    if model:\n",
        "        language_model = model\n",
        "    elif config:\n",
        "        language_model = factory.create_model(\n",
        "            config=config,\n",
        "            examples=prompt_template.examples if use_schema_constraints else None,\n",
        "            use_schema_constraints=use_schema_constraints,\n",
        "            fence_output=fence_output,\n",
        "        )\n",
        "    else:\n",
        "        # Cria config e usa factory\n",
        "        config = factory.ModelConfig(\n",
        "            model_id=model_id,\n",
        "            provider_kwargs=filtered_kwargs\n",
        "        )\n",
        "        language_model = factory.create_model(config=config, ...)\n",
        "    \n",
        "    # ============================================\n",
        "    # 5. SUBSISTEMA: FORMAT HANDLER\n",
        "    # ============================================\n",
        "    format_handler, remaining_params = fh.FormatHandler.from_resolver_params(\n",
        "        resolver_params=resolver_params,\n",
        "        base_format_type=format_type,\n",
        "        base_use_fences=language_model.requires_fence_output,\n",
        "        ...\n",
        "    )\n",
        "    \n",
        "    # ============================================\n",
        "    # 6. SUBSISTEMA: RESOLVER\n",
        "    # ============================================\n",
        "    res = resolver.Resolver(**effective_params)\n",
        "    \n",
        "    # ============================================\n",
        "    # 7. SUBSISTEMA: ANNOTATOR (pipeline principal)\n",
        "    # ============================================\n",
        "    annotator = annotation.Annotator(\n",
        "        language_model=language_model,\n",
        "        prompt_template=prompt_template,\n",
        "        format_handler=format_handler,\n",
        "    )\n",
        "    \n",
        "    # ============================================\n",
        "    # 8. EXECU√á√ÉO (coordena tudo)\n",
        "    # ============================================\n",
        "    if isinstance(text_or_documents, str):\n",
        "        return annotator.annotate_text(\n",
        "            text=text_or_documents,\n",
        "            resolver=res,\n",
        "            max_char_buffer=max_char_buffer,\n",
        "            batch_length=batch_length,\n",
        "            additional_context=additional_context,\n",
        "            extraction_passes=extraction_passes,\n",
        "            show_progress=show_progress,\n",
        "            **alignment_kwargs,\n",
        "        )\n",
        "    else:\n",
        "        return annotator.annotate_documents(\n",
        "            documents=text_or_documents,\n",
        "            resolver=res,\n",
        "            max_char_buffer=max_char_buffer,\n",
        "            batch_length=batch_length,\n",
        "            extraction_passes=extraction_passes,\n",
        "            show_progress=show_progress,\n",
        "            **alignment_kwargs,\n",
        "        )\n",
        "```\n",
        "\n",
        "### **B) Subsistemas Complexos que a Facade Esconde**\n",
        "\n",
        "```python\n",
        "# ============================================\n",
        "# SUBSISTEMA 1: Factory (factory.py)\n",
        "# ============================================\n",
        "class ModelConfig:\n",
        "    model_id: str\n",
        "    provider: str | None\n",
        "    provider_kwargs: dict\n",
        "\n",
        "def create_model(config: ModelConfig, ...) -> BaseLanguageModel:\n",
        "    # L√≥gica complexa de resolu√ß√£o de providers\n",
        "    providers.load_builtins_once()\n",
        "    providers.load_plugins_once()\n",
        "    provider_class = router.resolve(config.model_id)\n",
        "    kwargs = _kwargs_with_environment_defaults(...)\n",
        "    return provider_class(**kwargs)\n",
        "\n",
        "# ============================================\n",
        "# SUBSISTEMA 2: Prompting (prompting.py)\n",
        "# ============================================\n",
        "class PromptTemplateStructured:\n",
        "    description: str\n",
        "    examples: list[ExampleData]\n",
        "\n",
        "class QAPromptGenerator:\n",
        "    def render(self, question: str, ...) -> str:\n",
        "        # Constr√≥i prompt complexo com exemplos\n",
        "        ...\n",
        "\n",
        "# ============================================\n",
        "# SUBSISTEMA 3: FormatHandler (format_handler.py)\n",
        "# ============================================\n",
        "class FormatHandler:\n",
        "    def parse_output(self, text: str) -> Sequence[Mapping]:\n",
        "        # Parse JSON/YAML com fences, wrappers, etc.\n",
        "        ...\n",
        "\n",
        "# ============================================\n",
        "# SUBSISTEMA 4: Resolver (resolver.py)\n",
        "# ============================================\n",
        "class Resolver:\n",
        "    def resolve(self, input_text: str) -> Sequence[Extraction]:\n",
        "        # Converte string ‚Üí Extraction objects\n",
        "        ...\n",
        "    \n",
        "    def align(self, extractions, source_text, ...) -> Iterator[Extraction]:\n",
        "        # Alinha extra√ß√µes com texto fonte\n",
        "        ...\n",
        "\n",
        "# ============================================\n",
        "# SUBSISTEMA 5: Annotator (annotation.py)\n",
        "# ============================================\n",
        "class Annotator:\n",
        "    def annotate_text(self, text: str, ...) -> AnnotatedDocument:\n",
        "        # Pipeline completo: chunk ‚Üí prompt ‚Üí infer ‚Üí resolve ‚Üí align\n",
        "        ...\n",
        "\n",
        "# ============================================\n",
        "# SUBSISTEMA 6: Chunking (chunking.py)\n",
        "# ============================================\n",
        "class ChunkIterator:\n",
        "    def __next__(self) -> TextChunk:\n",
        "        # Divide texto em chunks respeitando buffer\n",
        "        ...\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üìä **3. COMPARA√á√ÉO DIRETA**\n",
        "\n",
        "| Aspecto | Facade Cl√°ssico | LangExtract `extract()` |\n",
        "|---------|-----------------|-------------------------|\n",
        "| **Interface √∫nica** | ‚úÖ `simple_operation()` | ‚úÖ `extract()` |\n",
        "| **Esconde subsistemas** | ‚úÖ SubsystemA, B, C | ‚úÖ Factory, Prompting, Resolver, etc. |\n",
        "| **Coordena opera√ß√µes** | ‚úÖ Chama m√∫ltiplos subsistemas | ‚úÖ Orquestra 6+ subsistemas |\n",
        "| **Simplifica uso** | ‚úÖ Cliente n√£o v√™ complexidade | ‚úÖ `lx.extract(text=\"...\", model_id=\"...\")` |\n",
        "| **Defaults inteligentes** | ‚ùå N√£o tem | ‚úÖ SIM (model_id padr√£o, etc.) |\n",
        "| **Valida√ß√£o** | ‚ùå N√£o tem | ‚úÖ SIM (examples, prompts) |\n",
        "| **Flexibilidade** | ‚ùå Interface fixa | ‚úÖ Muitos par√¢metros opcionais |\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ **4. MAPEAMENTO CONCEITUAL**\n",
        "\n",
        "```\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ  PADR√ÉO GoF          ‚Üí    LANGEXTRACT                  ‚îÇ\n",
        "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
        "‚îÇ  Facade              ‚Üí    extract()                    ‚îÇ\n",
        "‚îÇ  SubsystemA          ‚Üí    factory (create_model)       ‚îÇ\n",
        "‚îÇ  SubsystemB          ‚Üí    prompting (render prompts)   ‚îÇ\n",
        "‚îÇ  SubsystemC          ‚Üí    resolver (parse output)      ‚îÇ\n",
        "‚îÇ  SubsystemD          ‚Üí    annotator (pipeline)         ‚îÇ\n",
        "‚îÇ  SubsystemE          ‚Üí    format_handler (JSON/YAML)   ‚îÇ\n",
        "‚îÇ  SubsystemF          ‚Üí    chunking (divide texto)      ‚îÇ\n",
        "‚îÇ  simple_operation()  ‚Üí    extract(text, model_id, ...) ‚îÇ\n",
        "‚îÇ  Cliente             ‚Üí    Usu√°rio final                ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "```\n",
        "\n",
        "### **Diagrama de Depend√™ncias**\n",
        "\n",
        "```\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ  CLIENTE                                ‚îÇ\n",
        "‚îÇ  (Usu√°rio do LangExtract)               ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                 ‚îÇ\n",
        "                 ‚îÇ lx.extract(text=\"...\", model_id=\"gemini\")\n",
        "                 ‚îÇ\n",
        "                 ‚ñº\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ  FACADE: extract()                      ‚îÇ  ‚óÑ‚îÄ‚îÄ‚îÄ Interface Simples\n",
        "‚îÇ  (extraction.py)                        ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "         ‚îÇ\n",
        "         ‚îÇ Coordena subsistemas ‚Üì\n",
        "         ‚îÇ\n",
        "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "    ‚îÇ                                    ‚îÇ\n",
        "    ‚ñº                                    ‚ñº\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ  Factory    ‚îÇ                  ‚îÇ  Prompting  ‚îÇ\n",
        "‚îÇ  (criar     ‚îÇ                  ‚îÇ  (gerar     ‚îÇ\n",
        "‚îÇ   modelo)   ‚îÇ                  ‚îÇ   prompts)  ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "       ‚îÇ                                ‚îÇ\n",
        "       ‚ñº                                ‚ñº\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ  Router     ‚îÇ                  ‚îÇ  Format     ‚îÇ\n",
        "‚îÇ  (resolve   ‚îÇ                  ‚îÇ  Handler    ‚îÇ\n",
        "‚îÇ   provider) ‚îÇ                  ‚îÇ  (parse)    ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                                        ‚îÇ\n",
        "                                        ‚ñº\n",
        "                                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "                                 ‚îÇ  Resolver   ‚îÇ\n",
        "                                 ‚îÇ  (align)    ‚îÇ\n",
        "                                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                                        ‚îÇ\n",
        "                                        ‚ñº\n",
        "                                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "                                 ‚îÇ  Annotator  ‚îÇ\n",
        "                                 ‚îÇ  (pipeline) ‚îÇ\n",
        "                                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                                        ‚îÇ\n",
        "                                        ‚ñº\n",
        "                                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "                                 ‚îÇ  Chunking   ‚îÇ\n",
        "                                 ‚îÇ  (iterator) ‚îÇ\n",
        "                                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üí° **5. COMPARA√á√ÉO: COM vs SEM FACADE**\n",
        "\n",
        "### **‚ùå SEM Facade (Cliente faz tudo manualmente)**\n",
        "\n",
        "```python\n",
        "# Cliente precisa conhecer TODOS os subsistemas\n",
        "from langextract import factory, prompting, resolver, annotation\n",
        "from langextract import io, providers\n",
        "from langextract.core import format_handler as fh\n",
        "\n",
        "# 1. Download se necess√°rio\n",
        "if io.is_url(text):\n",
        "    text = io.download_text_from_url(text)\n",
        "\n",
        "# 2. Criar prompt template\n",
        "prompt_template = prompting.PromptTemplateStructured(\n",
        "    description=\"Extract entities\"\n",
        ")\n",
        "prompt_template.examples.extend(examples)\n",
        "\n",
        "# 3. Configurar e criar model\n",
        "providers.load_builtins_once()\n",
        "providers.load_plugins_once()\n",
        "config = factory.ModelConfig(\n",
        "    model_id=\"gemini-2.5-flash\",\n",
        "    provider_kwargs={\"api_key\": \"...\"}\n",
        ")\n",
        "language_model = factory.create_model(config)\n",
        "\n",
        "# 4. Criar format handler\n",
        "format_handler = fh.FormatHandler(\n",
        "    format_type=data.FormatType.JSON,\n",
        "    use_fences=language_model.requires_fence_output,\n",
        "    use_wrapper=True,\n",
        "    wrapper_key=\"extractions\"\n",
        ")\n",
        "\n",
        "# 5. Criar resolver\n",
        "res = resolver.Resolver(format_handler=format_handler)\n",
        "\n",
        "# 6. Criar annotator\n",
        "annotator = annotation.Annotator(\n",
        "    language_model=language_model,\n",
        "    prompt_template=prompt_template,\n",
        "    format_handler=format_handler\n",
        ")\n",
        "\n",
        "# 7. Executar anota√ß√£o\n",
        "result = annotator.annotate_text(\n",
        "    text=text,\n",
        "    resolver=res,\n",
        "    max_char_buffer=1000,\n",
        "    batch_length=10,\n",
        "    extraction_passes=1,\n",
        "    show_progress=True\n",
        ")\n",
        "\n",
        "# üò∞ Muito complexo para o usu√°rio!\n",
        "```\n",
        "\n",
        "### **‚úÖ COM Facade (Interface Simples)**\n",
        "\n",
        "```python\n",
        "import langextract as lx\n",
        "\n",
        "# Uma linha faz tudo!\n",
        "result = lx.extract(\n",
        "    text=\"Your document text here...\",\n",
        "    prompt_description=\"Extract entities\",\n",
        "    examples=[...],\n",
        "    model_id=\"gemini-2.5-flash\"\n",
        ")\n",
        "\n",
        "# üòä Simples e direto!\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üîß **6. EXEMPLO PR√ÅTICO COMPLETO**\n",
        "\n",
        "### **A) Facade Cl√°ssico (Sistema de Home Theater)**\n",
        "\n",
        "```python\n",
        "# ============================================\n",
        "# SUBSISTEMAS COMPLEXOS\n",
        "# ============================================\n",
        "\n",
        "class Amplifier:\n",
        "    def on(self): return \"Amplifier ligado\"\n",
        "    def set_volume(self, level): return f\"Volume: {level}\"\n",
        "    def off(self): return \"Amplifier desligado\"\n",
        "\n",
        "class DVDPlayer:\n",
        "    def on(self): return \"DVD ligado\"\n",
        "    def play(self, movie): return f\"Reproduzindo: {movie}\"\n",
        "    def stop(self): return \"DVD parado\"\n",
        "    def off(self): return \"DVD desligado\"\n",
        "\n",
        "class Projector:\n",
        "    def on(self): return \"Projetor ligado\"\n",
        "    def wide_screen_mode(self): return \"Modo widescreen\"\n",
        "    def off(self): return \"Projetor desligado\"\n",
        "\n",
        "class Lights:\n",
        "    def dim(self, level): return f\"Luzes: {level}%\"\n",
        "\n",
        "# ============================================\n",
        "# FACADE - Interface Simples\n",
        "# ============================================\n",
        "\n",
        "class HomeTheaterFacade:\n",
        "    \"\"\"Simplifica opera√ß√£o do home theater\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.amp = Amplifier()\n",
        "        self.dvd = DVDPlayer()\n",
        "        self.projector = Projector()\n",
        "        self.lights = Lights()\n",
        "    \n",
        "    def watch_movie(self, movie: str):\n",
        "        \"\"\"Uma chamada, m√∫ltiplas opera√ß√µes coordenadas\"\"\"\n",
        "        print(\"Preparando para assistir filme...\")\n",
        "        print(self.lights.dim(10))\n",
        "        print(self.projector.on())\n",
        "        print(self.projector.wide_screen_mode())\n",
        "        print(self.amp.on())\n",
        "        print(self.amp.set_volume(5))\n",
        "        print(self.dvd.on())\n",
        "        print(self.dvd.play(movie))\n",
        "    \n",
        "    def end_movie(self):\n",
        "        \"\"\"Desliga tudo de uma vez\"\"\"\n",
        "        print(\"Finalizando filme...\")\n",
        "        print(self.dvd.stop())\n",
        "        print(self.dvd.off())\n",
        "        print(self.amp.off())\n",
        "        print(self.projector.off())\n",
        "        print(self.lights.dim(100))\n",
        "\n",
        "# ============================================\n",
        "# USO\n",
        "# ============================================\n",
        "\n",
        "theater = HomeTheaterFacade()\n",
        "theater.watch_movie(\"Matrix\")  # ‚Üê Simples!\n",
        "# ... assistir filme ...\n",
        "theater.end_movie()  # ‚Üê Simples!\n",
        "```\n",
        "\n",
        "### **B) LangExtract Facade (Simplificado)**\n",
        "\n",
        "```python\n",
        "# ============================================\n",
        "# VERS√ÉO SIMPLIFICADA MOSTRANDO SUBSISTEMAS\n",
        "# ============================================\n",
        "\n",
        "class SimpleLangExtract:\n",
        "    \"\"\"Facade simplificada do LangExtract\"\"\"\n",
        "    \n",
        "    def extract(\n",
        "        self,\n",
        "        text: str,\n",
        "        prompt: str,\n",
        "        examples: list,\n",
        "        model_id: str = \"gemini-2.5-flash\"\n",
        "    ):\n",
        "        \"\"\"Interface simples que esconde 6 subsistemas\"\"\"\n",
        "        \n",
        "        # SUBSISTEMA 1: Prompting\n",
        "        prompt_template = self._create_prompt(prompt, examples)\n",
        "        \n",
        "        # SUBSISTEMA 2: Factory\n",
        "        model = self._create_model(model_id)\n",
        "        \n",
        "        # SUBSISTEMA 3: Format Handler\n",
        "        format_handler = self._create_format_handler(model)\n",
        "        \n",
        "        # SUBSISTEMA 4: Resolver\n",
        "        resolver = self._create_resolver(format_handler)\n",
        "        \n",
        "        # SUBSISTEMA 5: Annotator\n",
        "        annotator = self._create_annotator(model, prompt_template, format_handler)\n",
        "        \n",
        "        # SUBSISTEMA 6: Execu√ß√£o (usa Chunking internamente)\n",
        "        result = annotator.annotate_text(text, resolver)\n",
        "        \n",
        "        return result\n",
        "    \n",
        "    def _create_prompt(self, description, examples):\n",
        "        # L√≥gica complexa de prompting\n",
        "        return PromptTemplate(description, examples)\n",
        "    \n",
        "    def _create_model(self, model_id):\n",
        "        # L√≥gica complexa de factory + router + providers\n",
        "        return ModelFactory.create(model_id)\n",
        "    \n",
        "    def _create_format_handler(self, model):\n",
        "        # L√≥gica de parsing JSON/YAML\n",
        "        return FormatHandler(model.format_type)\n",
        "    \n",
        "    def _create_resolver(self, format_handler):\n",
        "        # L√≥gica de convers√£o string ‚Üí objetos\n",
        "        return Resolver(format_handler)\n",
        "    \n",
        "    def _create_annotator(self, model, prompt, format_handler):\n",
        "        # L√≥gica de pipeline de extra√ß√£o\n",
        "        return Annotator(model, prompt, format_handler)\n",
        "\n",
        "# ============================================\n",
        "# USO\n",
        "# ============================================\n",
        "\n",
        "lx = SimpleLangExtract()\n",
        "\n",
        "result = lx.extract(\n",
        "    text=\"Romeo loves Juliet\",\n",
        "    prompt=\"Extract relationships\",\n",
        "    examples=[...],\n",
        "    model_id=\"gemini-2.5-flash\"\n",
        ")  # ‚Üê Interface simples esconde toda complexidade!\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ **7. CHECKLIST DE VERIFICA√á√ÉO**\n",
        "\n",
        "| Caracter√≠stica do Facade Pattern | `extract()` |\n",
        "|-----------------------------------|-------------|\n",
        "| ‚úÖ Interface unificada de alto n√≠vel | ‚úÖ SIM |\n",
        "| ‚úÖ Esconde complexidade de subsistemas | ‚úÖ SIM (6+ subsistemas) |\n",
        "| ‚úÖ Coordena m√∫ltiplas opera√ß√µes | ‚úÖ SIM (factory ‚Üí prompting ‚Üí resolver ‚Üí annotator) |\n",
        "| ‚úÖ Simplifica uso para cliente | ‚úÖ SIM (1 linha vs 50+ linhas) |\n",
        "| ‚úÖ Subsistemas ainda acess√≠veis | ‚úÖ SIM (usu√°rios avan√ßados podem usar direto) |\n",
        "| ‚úÖ Reduz acoplamento | ‚úÖ SIM (cliente n√£o depende de subsistemas) |\n",
        "| ‚úÖ Facilita manuten√ß√£o | ‚úÖ SIM (mudan√ßas internas n√£o afetam API) |\n",
        "\n",
        "---\n",
        "\n",
        "## üìà **8. VANTAGENS DA IMPLEMENTA√á√ÉO**\n",
        "\n",
        "| Vantagem | Descri√ß√£o |\n",
        "|----------|-----------|\n",
        "| **Simplicidade** | API de 1 linha para opera√ß√£o complexa |\n",
        "| **Defaults inteligentes** | `model_id=\"gemini-2.5-flash\"`, par√¢metros opcionais |\n",
        "| **Flexibilidade** | Usu√°rios avan√ßados podem passar `model`, `config`, etc. |\n",
        "| **Valida√ß√£o** | Valida inputs antes de processar |\n",
        "| **Documenta√ß√£o clara** | Docstring explica todos os par√¢metros |\n",
        "| **Backward compatibility** | Warnings para par√¢metros deprecados |\n",
        "| **Extensibilidade** | Subsistemas podem evoluir independentemente |\n",
        "\n"
      ],
      "metadata": {
        "id": "uXpEtJ8JeGPO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üèóÔ∏è Builder Pattern - An√°lise LangExtract\n",
        "## Compara√ß√£o: prompting.py vs Padr√£o GoF\n",
        "\n",
        "---\n",
        "\n",
        "## üìö **1. PADR√ÉO BUILDER (GoF) - RESUMO**\n",
        "\n",
        "### **Defini√ß√£o**\n",
        "> Separa a constru√ß√£o de um objeto complexo de sua representa√ß√£o, permitindo que o mesmo processo de constru√ß√£o crie diferentes representa√ß√µes.\n",
        "\n",
        "### **Estrutura Cl√°ssica**\n",
        "\n",
        "```python\n",
        "from abc import ABC, abstractmethod\n",
        "\n",
        "# ============================================\n",
        "# PRODUTO - Objeto complexo a ser constru√≠do\n",
        "# ============================================\n",
        "\n",
        "class Pizza:\n",
        "    def __init__(self):\n",
        "        self.dough = None\n",
        "        self.sauce = None\n",
        "        self.topping = None\n",
        "    \n",
        "    def __str__(self):\n",
        "        return f\"Pizza: {self.dough}, {self.sauce}, {self.topping}\"\n",
        "\n",
        "# ============================================\n",
        "# BUILDER - Interface abstrata\n",
        "# ============================================\n",
        "\n",
        "class PizzaBuilder(ABC):\n",
        "    def __init__(self):\n",
        "        self.pizza = Pizza()\n",
        "    \n",
        "    @abstractmethod\n",
        "    def build_dough(self):\n",
        "        pass\n",
        "    \n",
        "    @abstractmethod\n",
        "    def build_sauce(self):\n",
        "        pass\n",
        "    \n",
        "    @abstractmethod\n",
        "    def build_topping(self):\n",
        "        pass\n",
        "    \n",
        "    def get_pizza(self) -> Pizza:\n",
        "        return self.pizza\n",
        "\n",
        "# ============================================\n",
        "# CONCRETE BUILDERS\n",
        "# ============================================\n",
        "\n",
        "class MargheritaBuilder(PizzaBuilder):\n",
        "    def build_dough(self):\n",
        "        self.pizza.dough = \"Massa fina\"\n",
        "        return self\n",
        "    \n",
        "    def build_sauce(self):\n",
        "        self.pizza.sauce = \"Molho de tomate\"\n",
        "        return self\n",
        "    \n",
        "    def build_topping(self):\n",
        "        self.pizza.topping = \"Mozzarella\"\n",
        "        return self\n",
        "\n",
        "class PepperoniBuilder(PizzaBuilder):\n",
        "    def build_dough(self):\n",
        "        self.pizza.dough = \"Massa grossa\"\n",
        "        return self\n",
        "    \n",
        "    def build_sauce(self):\n",
        "        self.pizza.sauce = \"Molho picante\"\n",
        "        return self\n",
        "    \n",
        "    def build_topping(self):\n",
        "        self.pizza.topping = \"Pepperoni\"\n",
        "        return self\n",
        "\n",
        "# ============================================\n",
        "# DIRECTOR (opcional) - Controla constru√ß√£o\n",
        "# ============================================\n",
        "\n",
        "class PizzaDirector:\n",
        "    def __init__(self, builder: PizzaBuilder):\n",
        "        self._builder = builder\n",
        "    \n",
        "    def make_pizza(self) -> Pizza:\n",
        "        \"\"\"Controla a ordem de constru√ß√£o\"\"\"\n",
        "        return (self._builder\n",
        "                .build_dough()\n",
        "                .build_sauce()\n",
        "                .build_topping()\n",
        "                .get_pizza())\n",
        "\n",
        "# ============================================\n",
        "# USO\n",
        "# ============================================\n",
        "\n",
        "# Com Director\n",
        "builder = MargheritaBuilder()\n",
        "director = PizzaDirector(builder)\n",
        "pizza = director.make_pizza()\n",
        "print(pizza)  # Pizza: Massa fina, Molho de tomate, Mozzarella\n",
        "\n",
        "# Sem Director (constru√ß√£o manual)\n",
        "builder = PepperoniBuilder()\n",
        "pizza = builder.build_dough().build_sauce().build_topping().get_pizza()\n",
        "print(pizza)  # Pizza: Massa grossa, Molho picante, Pepperoni\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üîç **2. BUILDER NO LANGEXTRACT (prompting.py)**\n",
        "\n",
        "### **A) QAPromptGenerator - O Builder**\n",
        "\n",
        "```python\n",
        "# ============================================\n",
        "# ARQUIVO: langextract/prompting.py\n",
        "# ============================================\n",
        "\n",
        "@dataclasses.dataclass\n",
        "class QAPromptGenerator:\n",
        "    \"\"\"\n",
        "    BUILDER: Constr√≥i prompts complexos incrementalmente.\n",
        "    \n",
        "    O produto final √© uma string de prompt formatada com:\n",
        "    - Descri√ß√£o/instru√ß√µes\n",
        "    - Contexto adicional (opcional)\n",
        "    - Exemplos few-shot formatados\n",
        "    - Pergunta\n",
        "    - Prefixos Q:/A:\n",
        "    \"\"\"\n",
        "    \n",
        "    # Componentes do prompt (configura√ß√£o)\n",
        "    template: PromptTemplateStructured\n",
        "    format_handler: FormatHandler\n",
        "    examples_heading: str = \"Examples\"\n",
        "    question_prefix: str = \"Q: \"\n",
        "    answer_prefix: str = \"A: \"\n",
        "    \n",
        "    def format_example_as_text(self, example: ExampleData) -> str:\n",
        "        \"\"\"\n",
        "        PASSO 1: Formata um √∫nico exemplo.\n",
        "        \n",
        "        Constr√≥i string com:\n",
        "        - Pergunta (Q: texto do exemplo)\n",
        "        - Resposta (A: extra√ß√µes formatadas)\n",
        "        \"\"\"\n",
        "        question = example.text\n",
        "        answer = self.format_handler.format_extraction_example(example.extractions)\n",
        "        \n",
        "        return \"\\n\".join([\n",
        "            f\"{self.question_prefix}{question}\",\n",
        "            f\"{self.answer_prefix}{answer}\\n\",\n",
        "        ])\n",
        "    \n",
        "    def render(self, question: str, additional_context: str | None = None) -> str:\n",
        "        \"\"\"\n",
        "        M√âTODO PRINCIPAL: Constr√≥i o prompt completo passo a passo.\n",
        "        \n",
        "        Builder Pattern aplicado:\n",
        "        1. Adiciona descri√ß√£o\n",
        "        2. Adiciona contexto (se houver)\n",
        "        3. Adiciona heading de exemplos\n",
        "        4. Adiciona cada exemplo formatado\n",
        "        5. Adiciona pergunta\n",
        "        6. Adiciona prefixo de resposta\n",
        "        \n",
        "        Retorna: String de prompt completa\n",
        "        \"\"\"\n",
        "        prompt_lines: list[str] = []\n",
        "        \n",
        "        # PASSO 1: Descri√ß√£o/Instru√ß√µes\n",
        "        prompt_lines.append(f\"{self.template.description}\\n\")\n",
        "        \n",
        "        # PASSO 2: Contexto adicional (opcional)\n",
        "        if additional_context:\n",
        "            prompt_lines.append(f\"{additional_context}\\n\")\n",
        "        \n",
        "        # PASSO 3: Se√ß√£o de exemplos\n",
        "        if self.template.examples:\n",
        "            prompt_lines.append(self.examples_heading)\n",
        "            \n",
        "            # PASSO 4: Cada exemplo formatado\n",
        "            for ex in self.template.examples:\n",
        "                prompt_lines.append(self.format_example_as_text(ex))\n",
        "        \n",
        "        # PASSO 5: Pergunta atual\n",
        "        prompt_lines.append(f\"{self.question_prefix}{question}\")\n",
        "        \n",
        "        # PASSO 6: Prefixo de resposta\n",
        "        prompt_lines.append(self.answer_prefix)\n",
        "        \n",
        "        # PRODUTO FINAL: String completa\n",
        "        return \"\\n\".join(prompt_lines)\n",
        "    \n",
        "    def __str__(self) -> str:\n",
        "        \"\"\"Renderiza com pergunta vazia (para visualiza√ß√£o)\"\"\"\n",
        "        return self.render(\"\")\n",
        "```\n",
        "\n",
        "### **B) PromptTemplateStructured - Configura√ß√£o do Builder**\n",
        "\n",
        "```python\n",
        "@dataclasses.dataclass\n",
        "class PromptTemplateStructured:\n",
        "    \"\"\"\n",
        "    Dados de entrada para o Builder.\n",
        "    \n",
        "    Armazena:\n",
        "    - description: Instru√ß√µes para o LLM\n",
        "    - examples: Lista de exemplos few-shot\n",
        "    \"\"\"\n",
        "    description: str\n",
        "    examples: list[ExampleData] = dataclasses.field(default_factory=list)\n",
        "```\n",
        "\n",
        "### **C) Produto Final - String de Prompt**\n",
        "\n",
        "```python\n",
        "# EXEMPLO DE PROMPT CONSTRU√çDO:\n",
        "\"\"\"\n",
        "Extract characters, emotions, and relationships in order of appearance.\n",
        "Use exact text for extractions. Do not paraphrase or overlap entities.\n",
        "\n",
        "Examples\n",
        "Q: ROMEO. But soft! What light through yonder window breaks?\n",
        "A: ```json\n",
        "{\n",
        "  \"extractions\": [\n",
        "    {\n",
        "      \"character\": \"ROMEO\",\n",
        "      \"character_attributes\": {\"emotional_state\": \"wonder\"}\n",
        "    },\n",
        "    {\n",
        "      \"emotion\": \"But soft!\",\n",
        "      \"emotion_attributes\": {\"feeling\": \"gentle awe\"}\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "```\n",
        "\n",
        "Q: Lady Juliet gazed longingly at the stars, her heart aching for Romeo\n",
        "A:\n",
        "\"\"\"\n",
        "# ‚Üê Builder construiu isso incrementalmente!\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üìä **3. COMPARA√á√ÉO DIRETA**\n",
        "\n",
        "| Aspecto | Builder Cl√°ssico | QAPromptGenerator |\n",
        "|---------|------------------|-------------------|\n",
        "| **Produto complexo** | `Pizza` (objeto) | `str` (prompt completo) |\n",
        "| **Constru√ß√£o incremental** | ‚úÖ M√©todos build_*() | ‚úÖ `prompt_lines.append()` |\n",
        "| **Passos separados** | ‚úÖ dough ‚Üí sauce ‚Üí topping | ‚úÖ description ‚Üí context ‚Üí examples ‚Üí question |\n",
        "| **Ordem importa** | ‚úÖ SIM | ‚úÖ SIM (descri√ß√£o primeiro, resposta por √∫ltimo) |\n",
        "| **Fluent interface** | ‚úÖ `return self` | ‚ùå N√£o (usa lista interna) |\n",
        "| **Configur√°vel** | ‚úÖ Diferentes builders | ‚úÖ Par√¢metros (prefixes, headings) |\n",
        "| **Produto final** | `get_pizza()` | `render()` retorna string |\n",
        "| **Director** | ‚úÖ `PizzaDirector` | ‚ùå N√£o tem (render() j√° √© o \"director\") |\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ **4. MAPEAMENTO CONCEITUAL**\n",
        "\n",
        "```\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ  PADR√ÉO GoF          ‚Üí    LANGEXTRACT                   ‚îÇ\n",
        "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
        "‚îÇ  Builder             ‚Üí    QAPromptGenerator             ‚îÇ\n",
        "‚îÇ  Product             ‚Üí    str (prompt completo)         ‚îÇ\n",
        "‚îÇ  build_dough()       ‚Üí    Adiciona description          ‚îÇ\n",
        "‚îÇ  build_sauce()       ‚Üí    Adiciona context              ‚îÇ\n",
        "‚îÇ  build_topping()     ‚Üí    Adiciona examples             ‚îÇ\n",
        "‚îÇ  build_extra()       ‚Üí    Adiciona question + prefix    ‚îÇ\n",
        "‚îÇ  get_product()       ‚Üí    render() retorna string       ‚îÇ\n",
        "‚îÇ  Director            ‚Üí    N√£o tem (render() coordena)   ‚îÇ\n",
        "‚îÇ  Configuration       ‚Üí    PromptTemplateStructured      ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "```\n",
        "\n",
        "### **Fluxo de Constru√ß√£o**\n",
        "\n",
        "```\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ  Cliente            ‚îÇ\n",
        "‚îÇ  (Annotator)        ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "           ‚îÇ\n",
        "           ‚îÇ prompt_generator.render(question)\n",
        "           ‚îÇ\n",
        "           ‚ñº\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ  QAPromptGenerator (Builder)            ‚îÇ\n",
        "‚îÇ  render() m√©todo coordena constru√ß√£o:   ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "           ‚îÇ\n",
        "           ‚îú‚îÄ 1. prompt_lines.append(description)\n",
        "           ‚îÇ\n",
        "           ‚îú‚îÄ 2. if context: prompt_lines.append(context)\n",
        "           ‚îÇ\n",
        "           ‚îú‚îÄ 3. prompt_lines.append(examples_heading)\n",
        "           ‚îÇ\n",
        "           ‚îú‚îÄ 4. for ex in examples:\n",
        "           ‚îÇ      prompt_lines.append(format_example_as_text(ex))\n",
        "           ‚îÇ\n",
        "           ‚îú‚îÄ 5. prompt_lines.append(question_prefix + question)\n",
        "           ‚îÇ\n",
        "           ‚îî‚îÄ 6. prompt_lines.append(answer_prefix)\n",
        "           ‚îÇ\n",
        "           ‚ñº\n",
        "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "    ‚îÇ  \"\\n\".join(...)  ‚îÇ  ‚óÑ‚îÄ‚îÄ‚îÄ Produto Final (String)\n",
        "    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üí° **5. DIFEREN√áAS PRINCIPAIS**\n",
        "\n",
        "### **A) Builder Cl√°ssico: M√∫ltiplos M√©todos**\n",
        "\n",
        "```python\n",
        "class PizzaBuilder:\n",
        "    def __init__(self):\n",
        "        self.pizza = Pizza()\n",
        "    \n",
        "    def build_dough(self):\n",
        "        self.pizza.dough = \"...\"  # ‚Üê M√©todo 1\n",
        "        return self\n",
        "    \n",
        "    def build_sauce(self):\n",
        "        self.pizza.sauce = \"...\"  # ‚Üê M√©todo 2\n",
        "        return self\n",
        "    \n",
        "    def build_topping(self):\n",
        "        self.pizza.topping = \"...\" # ‚Üê M√©todo 3\n",
        "        return self\n",
        "    \n",
        "    def get_pizza(self) -> Pizza:\n",
        "        return self.pizza  # ‚Üê Retorna produto\n",
        "\n",
        "# Uso: Constru√ß√£o expl√≠cita\n",
        "pizza = (builder\n",
        "         .build_dough()\n",
        "         .build_sauce()\n",
        "         .build_topping()\n",
        "         .get_pizza())\n",
        "```\n",
        "\n",
        "### **B) QAPromptGenerator: M√©todo √önico de Constru√ß√£o**\n",
        "\n",
        "```python\n",
        "class QAPromptGenerator:\n",
        "    def render(self, question: str, additional_context: str | None = None) -> str:\n",
        "        \"\"\"√önico m√©todo que coordena TODA constru√ß√£o\"\"\"\n",
        "        prompt_lines = []\n",
        "        \n",
        "        # PASSO 1\n",
        "        prompt_lines.append(self.template.description)\n",
        "        \n",
        "        # PASSO 2 (condicional)\n",
        "        if additional_context:\n",
        "            prompt_lines.append(additional_context)\n",
        "        \n",
        "        # PASSO 3\n",
        "        if self.template.examples:\n",
        "            prompt_lines.append(self.examples_heading)\n",
        "        \n",
        "        # PASSO 4 (loop)\n",
        "        for ex in self.template.examples:\n",
        "            prompt_lines.append(self.format_example_as_text(ex))\n",
        "        \n",
        "        # PASSO 5\n",
        "        prompt_lines.append(f\"{self.question_prefix}{question}\")\n",
        "        \n",
        "        # PASSO 6\n",
        "        prompt_lines.append(self.answer_prefix)\n",
        "        \n",
        "        # PRODUTO FINAL\n",
        "        return \"\\n\".join(prompt_lines)\n",
        "\n",
        "# Uso: Uma chamada\n",
        "prompt = generator.render(question=\"Extract entities from...\")\n",
        "```\n",
        "\n",
        "**Por que a diferen√ßa?**\n",
        "- Builder cl√°ssico: Flexibilidade m√°xima (cliente controla ordem)\n",
        "- QAPromptGenerator: Ordem fixa faz sentido (descri√ß√£o sempre primeiro)\n",
        "- Prompts t√™m estrutura previs√≠vel (n√£o precisam de fluent interface)\n",
        "\n",
        "---\n",
        "\n",
        "## üîß **6. EXEMPLO PR√ÅTICO COMPLETO**\n",
        "\n",
        "### **A) Builder Cl√°ssico (Constru√ß√£o de Email)**\n",
        "\n",
        "```python\n",
        "# ============================================\n",
        "# PRODUTO\n",
        "# ============================================\n",
        "\n",
        "class Email:\n",
        "    def __init__(self):\n",
        "        self.to = None\n",
        "        self.subject = None\n",
        "        self.body = None\n",
        "        self.attachments = []\n",
        "    \n",
        "    def __str__(self):\n",
        "        return f\"To: {self.to}\\nSubject: {self.subject}\\n\\n{self.body}\"\n",
        "\n",
        "# ============================================\n",
        "# BUILDER\n",
        "# ============================================\n",
        "\n",
        "class EmailBuilder:\n",
        "    def __init__(self):\n",
        "        self.email = Email()\n",
        "    \n",
        "    def to(self, recipient: str):\n",
        "        self.email.to = recipient\n",
        "        return self\n",
        "    \n",
        "    def subject(self, subject: str):\n",
        "        self.email.subject = subject\n",
        "        return self\n",
        "    \n",
        "    def body(self, body: str):\n",
        "        self.email.body = body\n",
        "        return self\n",
        "    \n",
        "    def attach(self, filename: str):\n",
        "        self.email.attachments.append(filename)\n",
        "        return self\n",
        "    \n",
        "    def build(self) -> Email:\n",
        "        return self.email\n",
        "\n",
        "# ============================================\n",
        "# USO - Fluent Interface\n",
        "# ============================================\n",
        "\n",
        "email = (EmailBuilder()\n",
        "         .to(\"user@example.com\")\n",
        "         .subject(\"Hello\")\n",
        "         .body(\"How are you?\")\n",
        "         .attach(\"report.pdf\")\n",
        "         .build())\n",
        "\n",
        "print(email)\n",
        "```\n",
        "\n",
        "### **B) QAPromptGenerator (Real do LangExtract)**\n",
        "\n",
        "```python\n",
        "# ============================================\n",
        "# CONFIGURA√á√ÉO\n",
        "# ============================================\n",
        "\n",
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class ExampleData:\n",
        "    text: str\n",
        "    extractions: list\n",
        "\n",
        "@dataclass\n",
        "class PromptTemplateStructured:\n",
        "    description: str\n",
        "    examples: list[ExampleData]\n",
        "\n",
        "# ============================================\n",
        "# BUILDER\n",
        "# ============================================\n",
        "\n",
        "class QAPromptGenerator:\n",
        "    def __init__(\n",
        "        self,\n",
        "        template: PromptTemplateStructured,\n",
        "        examples_heading: str = \"Examples\",\n",
        "        question_prefix: str = \"Q: \",\n",
        "        answer_prefix: str = \"A: \"\n",
        "    ):\n",
        "        self.template = template\n",
        "        self.examples_heading = examples_heading\n",
        "        self.question_prefix = question_prefix\n",
        "        self.answer_prefix = answer_prefix\n",
        "    \n",
        "    def format_example_as_text(self, example: ExampleData) -> str:\n",
        "        \"\"\"Formata um exemplo como Q:/A:\"\"\"\n",
        "        return (\n",
        "            f\"{self.question_prefix}{example.text}\\n\"\n",
        "            f\"{self.answer_prefix}{example.extractions}\\n\"\n",
        "        )\n",
        "    \n",
        "    def render(self, question: str, additional_context: str | None = None) -> str:\n",
        "        \"\"\"Constr√≥i prompt completo\"\"\"\n",
        "        lines = []\n",
        "        \n",
        "        # 1. Descri√ß√£o\n",
        "        lines.append(f\"{self.template.description}\\n\")\n",
        "        \n",
        "        # 2. Contexto (opcional)\n",
        "        if additional_context:\n",
        "            lines.append(f\"{additional_context}\\n\")\n",
        "        \n",
        "        # 3. Exemplos\n",
        "        if self.template.examples:\n",
        "            lines.append(self.examples_heading)\n",
        "            for ex in self.template.examples:\n",
        "                lines.append(self.format_example_as_text(ex))\n",
        "        \n",
        "        # 4. Pergunta\n",
        "        lines.append(f\"{self.question_prefix}{question}\")\n",
        "        \n",
        "        # 5. Prefixo resposta\n",
        "        lines.append(self.answer_prefix)\n",
        "        \n",
        "        return \"\\n\".join(lines)\n",
        "\n",
        "# ============================================\n",
        "# USO\n",
        "# ============================================\n",
        "\n",
        "template = PromptTemplateStructured(\n",
        "    description=\"Extract entities from text:\",\n",
        "    examples=[\n",
        "        ExampleData(\n",
        "            text=\"Alice loves Bob\",\n",
        "            extractions=[\"Alice\", \"Bob\", \"loves\"]\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "\n",
        "generator = QAPromptGenerator(template)\n",
        "prompt = generator.render(\n",
        "    question=\"Romeo sees Juliet\",\n",
        "    additional_context=\"Focus on names\"\n",
        ")\n",
        "\n",
        "print(prompt)\n",
        "# Output:\n",
        "# Extract entities from text:\n",
        "#\n",
        "# Focus on names\n",
        "#\n",
        "# Examples\n",
        "# Q: Alice loves Bob\n",
        "# A: [\"Alice\", \"Bob\", \"loves\"]\n",
        "#\n",
        "# Q: Romeo sees Juliet\n",
        "# A:\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ **7. CHECKLIST DE VERIFICA√á√ÉO**\n",
        "\n",
        "| Caracter√≠stica do Builder Pattern | QAPromptGenerator |\n",
        "|------------------------------------|-------------------|\n",
        "| ‚úÖ Constr√≥i objeto complexo | ‚úÖ SIM (prompt multi-se√ß√£o) |\n",
        "| ‚úÖ Constru√ß√£o incremental | ‚úÖ SIM (append linha por linha) |\n",
        "| ‚úÖ Separa constru√ß√£o de representa√ß√£o | ‚úÖ SIM (render() vs template data) |\n",
        "| ‚úÖ Passos bem definidos | ‚úÖ SIM (6 passos claros) |\n",
        "| ‚úÖ Ordem de constru√ß√£o controlada | ‚úÖ SIM (descri√ß√£o ‚Üí exemplos ‚Üí quest√£o) |\n",
        "| ‚úÖ Produto complexo final | ‚úÖ SIM (string formatada) |\n",
        "| ‚ùå Fluent interface (return self) | ‚ùå N√ÉO (usa lista interna) |\n",
        "| ‚ùå Classe Director separada | ‚ùå N√ÉO (render() j√° √© o director) |\n",
        "\n",
        "---\n",
        "\n",
        "## üìà **8. VANTAGENS DA IMPLEMENTA√á√ÉO**\n",
        "\n",
        "| Vantagem | Descri√ß√£o |\n",
        "|----------|-----------|\n",
        "| **Ordem garantida** | Descri√ß√£o sempre primeiro, resposta sempre √∫ltima |\n",
        "| **Configur√°vel** | Prefixes, headings customiz√°veis |\n",
        "| **Reutiliz√°vel** | Mesmo generator para m√∫ltiplas perguntas |\n",
        "| **Separa√ß√£o de concerns** | Template (dados) vs Generator (constru√ß√£o) |\n",
        "| **Test√°vel** | Pode testar cada passo individualmente |\n",
        "| **Legibilidade** | C√≥digo sequencial claro |\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ **9. VARIA√á√ïES DO PADR√ÉO**\n",
        "\n",
        "### **A) Builder Cl√°ssico (GoF)**\n",
        "```python\n",
        "# M√∫ltiplos m√©todos build_*()\n",
        "# Fluent interface (return self)\n",
        "# get_product() expl√≠cito\n",
        "\n",
        "builder = EmailBuilder()\n",
        "email = (builder\n",
        "         .to(\"...\")\n",
        "         .subject(\"...\")\n",
        "         .body(\"...\")\n",
        "         .build())  # ‚Üê get_product()\n",
        "```\n",
        "\n",
        "### **B) Telescoping Constructor (Anti-pattern)**\n",
        "```python\n",
        "# ‚ùå ANTIPADR√ÉO - Muitos par√¢metros\n",
        "prompt = create_prompt(\n",
        "    description=\"...\",\n",
        "    context=\"...\",\n",
        "    examples=[...],\n",
        "    examples_heading=\"...\",\n",
        "    question_prefix=\"...\",\n",
        "    answer_prefix=\"...\",\n",
        "    question=\"...\",\n",
        ")\n",
        "# Dif√≠cil de ler e manter!\n",
        "```\n",
        "\n",
        "### **C) QAPromptGenerator (Builder Simplificado)**\n",
        "```python\n",
        "# ‚úÖ Builder interno\n",
        "# M√©todo √∫nico render()\n",
        "# Ordem fixa de passos\n",
        "\n",
        "generator = QAPromptGenerator(template)\n",
        "prompt = generator.render(question=\"...\")  # ‚Üê Tudo em uma chamada\n",
        "```\n",
        "\n",
        "**Por que QAPromptGenerator √© Builder?**\n",
        "- Constr√≥i produto complexo (prompt) passo a passo\n",
        "- Separa configura√ß√£o (template) de constru√ß√£o (render)\n",
        "- Encapsula l√≥gica de formata√ß√£o\n",
        "- Ordem de passos bem definida\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0CI0DDf3e8FA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üéØ Strategy Pattern - An√°lise LangExtract\n",
        "## Compara√ß√£o: base_model.py + Implementa√ß√µes (gemini.py, openai.py, ollama.py) vs Padr√£o GoF\n",
        "\n",
        "---\n",
        "\n",
        "## üìö **1. PADR√ÉO STRATEGY (GoF) - RESUMO**\n",
        "\n",
        "### **Defini√ß√£o**\n",
        "> Define uma fam√≠lia de algoritmos, encapsula cada um deles e os torna intercambi√°veis. Strategy permite que o algoritmo varie independentemente dos clientes que o utilizam.\n",
        "\n",
        "### **Estrutura Cl√°ssica**\n",
        "\n",
        "```python\n",
        "from abc import ABC, abstractmethod\n",
        "\n",
        "# ============================================\n",
        "# STRATEGY - Interface abstrata\n",
        "# ============================================\n",
        "\n",
        "class CompressionStrategy(ABC):\n",
        "    \"\"\"Interface comum para todas as estrat√©gias de compress√£o\"\"\"\n",
        "    \n",
        "    @abstractmethod\n",
        "    def compress(self, data: str) -> bytes:\n",
        "        \"\"\"Comprime dados usando algoritmo espec√≠fico\"\"\"\n",
        "        pass\n",
        "\n",
        "# ============================================\n",
        "# CONCRETE STRATEGIES - Implementa√ß√µes\n",
        "# ============================================\n",
        "\n",
        "class ZipCompression(CompressionStrategy):\n",
        "    \"\"\"Estrat√©gia concreta: Compress√£o ZIP\"\"\"\n",
        "    \n",
        "    def compress(self, data: str) -> bytes:\n",
        "        # Algoritmo ZIP\n",
        "        return f\"ZIP({data})\".encode()\n",
        "\n",
        "class RarCompression(CompressionStrategy):\n",
        "    \"\"\"Estrat√©gia concreta: Compress√£o RAR\"\"\"\n",
        "    \n",
        "    def compress(self, data: str) -> bytes:\n",
        "        # Algoritmo RAR\n",
        "        return f\"RAR({data})\".encode()\n",
        "\n",
        "class GzipCompression(CompressionStrategy):\n",
        "    \"\"\"Estrat√©gia concreta: Compress√£o GZIP\"\"\"\n",
        "    \n",
        "    def compress(self, data: str) -> bytes:\n",
        "        # Algoritmo GZIP\n",
        "        return f\"GZIP({data})\".encode()\n",
        "\n",
        "# ============================================\n",
        "# CONTEXT - Classe que usa Strategy\n",
        "# ============================================\n",
        "\n",
        "class FileCompressor:\n",
        "    \"\"\"Context: Usa estrat√©gia de compress√£o\"\"\"\n",
        "    \n",
        "    def __init__(self, strategy: CompressionStrategy):\n",
        "        self._strategy = strategy\n",
        "    \n",
        "    def set_strategy(self, strategy: CompressionStrategy):\n",
        "        \"\"\"Troca estrat√©gia em tempo de execu√ß√£o\"\"\"\n",
        "        self._strategy = strategy\n",
        "    \n",
        "    def compress_file(self, data: str) -> bytes:\n",
        "        \"\"\"Delega compress√£o para estrat√©gia atual\"\"\"\n",
        "        print(f\"Usando estrat√©gia: {self._strategy.__class__.__name__}\")\n",
        "        return self._strategy.compress(data)\n",
        "\n",
        "# ============================================\n",
        "# USO - Cliente escolhe estrat√©gia\n",
        "# ============================================\n",
        "\n",
        "# Cliente escolhe ZIP\n",
        "compressor = FileCompressor(ZipCompression())\n",
        "result1 = compressor.compress_file(\"Hello World\")\n",
        "print(result1)  # b'ZIP(Hello World)'\n",
        "\n",
        "# Troca para RAR em runtime\n",
        "compressor.set_strategy(RarCompression())\n",
        "result2 = compressor.compress_file(\"Hello World\")\n",
        "print(result2)  # b'RAR(Hello World)'\n",
        "\n",
        "# Troca para GZIP\n",
        "compressor.set_strategy(GzipCompression())\n",
        "result3 = compressor.compress_file(\"Hello World\")\n",
        "print(result3)  # b'GZIP(Hello World)'\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üîç **2. STRATEGY NO LANGEXTRACT**\n",
        "\n",
        "### **A) BaseLanguageModel - A Interface Strategy**\n",
        "\n",
        "```python\n",
        "# ============================================\n",
        "# ARQUIVO: langextract/core/base_model.py\n",
        "# ============================================\n",
        "\n",
        "class BaseLanguageModel(abc.ABC):\n",
        "    \"\"\"\n",
        "    STRATEGY INTERFACE: Interface abstrata para LLMs.\n",
        "    \n",
        "    Define contrato comum para todas as estrat√©gias (providers):\n",
        "    - infer() ‚Üí M√©todo principal (algoritmo intercambi√°vel)\n",
        "    - parse_output() ‚Üí Parsing de resposta\n",
        "    - merge_kwargs() ‚Üí Configura√ß√£o\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, constraint: types.Constraint | None = None, **kwargs: Any):\n",
        "        \"\"\"Inicializa com configura√ß√£o base\"\"\"\n",
        "        self._constraint = constraint or types.Constraint()\n",
        "        self._schema: schema.BaseSchema | None = None\n",
        "        self._extra_kwargs: dict[str, Any] = kwargs.copy()\n",
        "    \n",
        "    @abc.abstractmethod\n",
        "    def infer(\n",
        "        self,\n",
        "        batch_prompts: Sequence[str],\n",
        "        **kwargs\n",
        "    ) -> Iterator[Sequence[types.ScoredOutput]]:\n",
        "        \"\"\"\n",
        "        ALGORITMO INTERCAMBI√ÅVEL: Infer√™ncia do LLM.\n",
        "        \n",
        "        Cada provider implementa SEU algoritmo:\n",
        "        - Gemini: Usa google-genai SDK\n",
        "        - OpenAI: Usa openai SDK\n",
        "        - Ollama: Usa HTTP requests\n",
        "        \n",
        "        Args:\n",
        "            batch_prompts: Lista de prompts\n",
        "            **kwargs: Par√¢metros espec√≠ficos (temperature, etc.)\n",
        "        \n",
        "        Returns:\n",
        "            Iterator de outputs com scores\n",
        "        \"\"\"\n",
        "    \n",
        "    def parse_output(self, output: str) -> Any:\n",
        "        \"\"\"M√©todo comum (n√£o abstrato) - pode ser sobrescrito\"\"\"\n",
        "        format_type = getattr(self, 'format_type', types.FormatType.JSON)\n",
        "        \n",
        "        try:\n",
        "            if format_type == types.FormatType.JSON:\n",
        "                return json.loads(output)\n",
        "            else:\n",
        "                return yaml.safe_load(output)\n",
        "        except Exception as e:\n",
        "            raise ValueError(f'Failed to parse output: {str(e)}') from e\n",
        "    \n",
        "    def merge_kwargs(self, runtime_kwargs: Mapping[str, Any] | None = None) -> dict:\n",
        "        \"\"\"M√©todo comum - merge de par√¢metros\"\"\"\n",
        "        base = getattr(self, '_extra_kwargs', {}) or {}\n",
        "        incoming = dict(runtime_kwargs or {})\n",
        "        return {**base, **incoming}\n",
        "```\n",
        "\n",
        "### **B) Concrete Strategy 1: GeminiLanguageModel**\n",
        "\n",
        "```python\n",
        "# ============================================\n",
        "# ARQUIVO: langextract/providers/gemini.py\n",
        "# ============================================\n",
        "\n",
        "class GeminiLanguageModel(base_model.BaseLanguageModel):\n",
        "    \"\"\"\n",
        "    CONCRETE STRATEGY 1: Implementa√ß√£o Google Gemini.\n",
        "    \n",
        "    Algoritmo espec√≠fico:\n",
        "    - Usa SDK google-genai\n",
        "    - Suporta structured output (JSON schema)\n",
        "    - Parallel processing com ThreadPoolExecutor\n",
        "    \"\"\"\n",
        "    \n",
        "    model_id: str = 'gemini-2.5-flash'\n",
        "    api_key: str | None = None\n",
        "    temperature: float = 0.0\n",
        "    max_workers: int = 10\n",
        "    \n",
        "    def __init__(\n",
        "        self,\n",
        "        model_id: str = 'gemini-2.5-flash',\n",
        "        api_key: str | None = None,\n",
        "        temperature: float = 0.0,\n",
        "        **kwargs\n",
        "    ):\n",
        "        \"\"\"Inicializa cliente Gemini\"\"\"\n",
        "        from google import genai\n",
        "        \n",
        "        self.model_id = model_id\n",
        "        self.api_key = api_key\n",
        "        self.temperature = temperature\n",
        "        \n",
        "        # Cliente Gemini SDK\n",
        "        self._client = genai.Client(\n",
        "            api_key=self.api_key,\n",
        "            vertexai=False,\n",
        "        )\n",
        "        \n",
        "        super().__init__(constraint=schema.Constraint())\n",
        "    \n",
        "    def infer(\n",
        "        self,\n",
        "        batch_prompts: Sequence[str],\n",
        "        **kwargs\n",
        "    ) -> Iterator[Sequence[core_types.ScoredOutput]]:\n",
        "        \"\"\"\n",
        "        ALGORITMO GEMINI: Infer√™ncia via Google Genai SDK.\n",
        "        \n",
        "        Espec√≠fico do Gemini:\n",
        "        - Parallel processing (ThreadPoolExecutor)\n",
        "        - response_schema para structured output\n",
        "        - response_mime_type: application/json\n",
        "        \"\"\"\n",
        "        config = {\n",
        "            'temperature': kwargs.get('temperature', self.temperature),\n",
        "        }\n",
        "        \n",
        "        # Gemini-specific: JSON schema support\n",
        "        if self.gemini_schema:\n",
        "            config['response_mime_type'] = 'application/json'\n",
        "            config['response_schema'] = self.gemini_schema.schema_dict\n",
        "        \n",
        "        # Parallel processing (Gemini-specific optimization)\n",
        "        if len(batch_prompts) > 1 and self.max_workers > 1:\n",
        "            with concurrent.futures.ThreadPoolExecutor(\n",
        "                max_workers=min(self.max_workers, len(batch_prompts))\n",
        "            ) as executor:\n",
        "                futures = {\n",
        "                    executor.submit(self._process_single_prompt, p, config): i\n",
        "                    for i, p in enumerate(batch_prompts)\n",
        "                }\n",
        "                \n",
        "                results = [None] * len(batch_prompts)\n",
        "                for future in concurrent.futures.as_completed(futures):\n",
        "                    idx = futures[future]\n",
        "                    results[idx] = future.result()\n",
        "                \n",
        "                for result in results:\n",
        "                    yield [result]\n",
        "        else:\n",
        "            # Sequential processing\n",
        "            for prompt in batch_prompts:\n",
        "                result = self._process_single_prompt(prompt, config)\n",
        "                yield [result]\n",
        "    \n",
        "    def _process_single_prompt(self, prompt: str, config: dict):\n",
        "        \"\"\"Processa um √∫nico prompt via Gemini API\"\"\"\n",
        "        response = self._client.models.generate_content(\n",
        "            model=self.model_id,\n",
        "            contents=prompt,\n",
        "            config=config\n",
        "        )\n",
        "        return core_types.ScoredOutput(score=1.0, output=response.text)\n",
        "```\n",
        "\n",
        "### **C) Concrete Strategy 2: OpenAILanguageModel**\n",
        "\n",
        "```python\n",
        "# ============================================\n",
        "# ARQUIVO: langextract/providers/openai.py\n",
        "# ============================================\n",
        "\n",
        "class OpenAILanguageModel(base_model.BaseLanguageModel):\n",
        "    \"\"\"\n",
        "    CONCRETE STRATEGY 2: Implementa√ß√£o OpenAI.\n",
        "    \n",
        "    Algoritmo espec√≠fico:\n",
        "    - Usa SDK openai\n",
        "    - JSON mode (response_format)\n",
        "    - Reasoning effort para o1/o3 models\n",
        "    \"\"\"\n",
        "    \n",
        "    model_id: str = 'gpt-4o-mini'\n",
        "    api_key: str | None = None\n",
        "    temperature: float | None = None\n",
        "    \n",
        "    def __init__(\n",
        "        self,\n",
        "        model_id: str = 'gpt-4o-mini',\n",
        "        api_key: str | None = None,\n",
        "        temperature: float | None = None,\n",
        "        **kwargs\n",
        "    ):\n",
        "        \"\"\"Inicializa cliente OpenAI\"\"\"\n",
        "        import openai\n",
        "        \n",
        "        self.model_id = model_id\n",
        "        self.api_key = api_key\n",
        "        self.temperature = temperature\n",
        "        \n",
        "        # Cliente OpenAI SDK\n",
        "        self._client = openai.OpenAI(api_key=self.api_key)\n",
        "        \n",
        "        super().__init__(constraint=schema.Constraint())\n",
        "    \n",
        "    def infer(\n",
        "        self,\n",
        "        batch_prompts: Sequence[str],\n",
        "        **kwargs\n",
        "    ) -> Iterator[Sequence[core_types.ScoredOutput]]:\n",
        "        \"\"\"\n",
        "        ALGORITMO OPENAI: Infer√™ncia via OpenAI SDK.\n",
        "        \n",
        "        Espec√≠fico do OpenAI:\n",
        "        - Chat completions API\n",
        "        - response_format: json_object\n",
        "        - reasoning_effort para o1 models\n",
        "        \"\"\"\n",
        "        config = {}\n",
        "        \n",
        "        if (temp := kwargs.get('temperature', self.temperature)) is not None:\n",
        "            config['temperature'] = temp\n",
        "        \n",
        "        # OpenAI-specific: JSON mode\n",
        "        if self.format_type == data.FormatType.JSON:\n",
        "            config.setdefault('response_format', {'type': 'json_object'})\n",
        "        \n",
        "        # OpenAI-specific: Reasoning effort (o1 models)\n",
        "        if 'reasoning_effort' in kwargs:\n",
        "            config['reasoning'] = {'effort': kwargs['reasoning_effort']}\n",
        "        \n",
        "        # Parallel ou sequential\n",
        "        for prompt in batch_prompts:\n",
        "            result = self._process_single_prompt(prompt, config)\n",
        "            yield [result]\n",
        "    \n",
        "    def _process_single_prompt(self, prompt: str, config: dict):\n",
        "        \"\"\"Processa um √∫nico prompt via OpenAI API\"\"\"\n",
        "        messages = [\n",
        "            {'role': 'system', 'content': 'You respond in JSON format.'},\n",
        "            {'role': 'user', 'content': prompt}\n",
        "        ]\n",
        "        \n",
        "        response = self._client.chat.completions.create(\n",
        "            model=self.model_id,\n",
        "            messages=messages,\n",
        "            **config\n",
        "        )\n",
        "        \n",
        "        output = response.choices[0].message.content\n",
        "        return core_types.ScoredOutput(score=1.0, output=output)\n",
        "    \n",
        "    @property\n",
        "    def requires_fence_output(self) -> bool:\n",
        "        \"\"\"OpenAI JSON mode retorna JSON puro (sem fences)\"\"\"\n",
        "        if self.format_type == data.FormatType.JSON:\n",
        "            return False  # ‚Üê Comportamento espec√≠fico OpenAI\n",
        "        return super().requires_fence_output\n",
        "```\n",
        "\n",
        "### **D) Concrete Strategy 3: OllamaLanguageModel**\n",
        "\n",
        "```python\n",
        "# ============================================\n",
        "# ARQUIVO: langextract/providers/ollama.py\n",
        "# ============================================\n",
        "\n",
        "class OllamaLanguageModel(base_model.BaseLanguageModel):\n",
        "    \"\"\"\n",
        "    CONCRETE STRATEGY 3: Implementa√ß√£o Ollama (local).\n",
        "    \n",
        "    Algoritmo espec√≠fico:\n",
        "    - Usa HTTP requests (n√£o tem SDK oficial)\n",
        "    - API local (localhost:11434)\n",
        "    - JSON format mode\n",
        "    \"\"\"\n",
        "    \n",
        "    _model: str\n",
        "    _model_url: str = 'http://localhost:11434'\n",
        "    format_type: core_types.FormatType = core_types.FormatType.JSON\n",
        "    \n",
        "    def __init__(\n",
        "        self,\n",
        "        model_id: str,\n",
        "        model_url: str = 'http://localhost:11434',\n",
        "        format_type: core_types.FormatType = core_types.FormatType.JSON,\n",
        "        **kwargs\n",
        "    ):\n",
        "        \"\"\"Inicializa cliente Ollama (HTTP)\"\"\"\n",
        "        self._model = model_id\n",
        "        self._model_url = model_url\n",
        "        self.format_type = format_type\n",
        "        self._requests = requests  # HTTP client\n",
        "        \n",
        "        super().__init__(constraint=schema.Constraint())\n",
        "    \n",
        "    def infer(\n",
        "        self,\n",
        "        batch_prompts: Sequence[str],\n",
        "        **kwargs\n",
        "    ) -> Iterator[Sequence[core_types.ScoredOutput]]:\n",
        "        \"\"\"\n",
        "        ALGORITMO OLLAMA: Infer√™ncia via HTTP requests.\n",
        "        \n",
        "        Espec√≠fico do Ollama:\n",
        "        - POST para /api/generate\n",
        "        - format: 'json' no payload\n",
        "        - Timeout configur√°vel\n",
        "        \"\"\"\n",
        "        for prompt in batch_prompts:\n",
        "            try:\n",
        "                response = self._ollama_query(\n",
        "                    prompt=prompt,\n",
        "                    model=self._model,\n",
        "                    structured_output_format='json',\n",
        "                    model_url=self._model_url,\n",
        "                    **kwargs\n",
        "                )\n",
        "                yield [core_types.ScoredOutput(\n",
        "                    score=1.0,\n",
        "                    output=response['response']\n",
        "                )]\n",
        "            except Exception as e:\n",
        "                raise exceptions.InferenceRuntimeError(\n",
        "                    f'Ollama API error: {str(e)}'\n",
        "                ) from e\n",
        "    \n",
        "    def _ollama_query(\n",
        "        self,\n",
        "        prompt: str,\n",
        "        model: str,\n",
        "        structured_output_format: str,\n",
        "        model_url: str,\n",
        "        **kwargs\n",
        "    ) -> dict:\n",
        "        \"\"\"\n",
        "        Query Ollama via HTTP POST.\n",
        "        \n",
        "        Ollama-specific implementation:\n",
        "        - Endpoint: /api/generate\n",
        "        - Payload: {model, prompt, format, options}\n",
        "        \"\"\"\n",
        "        api_url = urljoin(model_url, 'api/generate')\n",
        "        \n",
        "        payload = {\n",
        "            'model': model,\n",
        "            'prompt': prompt,\n",
        "            'stream': False,  # ‚Üê Ollama-specific\n",
        "            'format': structured_output_format,  # ‚Üê Ollama JSON mode\n",
        "            'options': {\n",
        "                'temperature': kwargs.get('temperature', 0.1),\n",
        "                'num_ctx': kwargs.get('num_ctx', 2048),\n",
        "            }\n",
        "        }\n",
        "        \n",
        "        # HTTP POST (sem SDK oficial)\n",
        "        response = self._requests.post(\n",
        "            api_url,\n",
        "            json=payload,\n",
        "            timeout=kwargs.get('timeout', 120)\n",
        "        )\n",
        "        \n",
        "        if response.status_code == 200:\n",
        "            return response.json()\n",
        "        elif response.status_code == 404:\n",
        "            raise exceptions.InferenceConfigError(\n",
        "                f\"Model {model} not found. Try: ollama run {model}\"\n",
        "            )\n",
        "        else:\n",
        "            raise exceptions.InferenceRuntimeError(\n",
        "                f'Ollama error: {response.status_code}'\n",
        "            )\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üìä **3. COMPARA√á√ÉO DIRETA**\n",
        "\n",
        "| Aspecto | Strategy Cl√°ssico | LangExtract |\n",
        "|---------|-------------------|-------------|\n",
        "| **Interface abstrata** | `CompressionStrategy` | `BaseLanguageModel` |\n",
        "| **M√©todo abstrato** | `compress(data)` | `infer(batch_prompts, **kwargs)` |\n",
        "| **Concrete Strategy 1** | `ZipCompression` | `GeminiLanguageModel` |\n",
        "| **Concrete Strategy 2** | `RarCompression` | `OpenAILanguageModel` |\n",
        "| **Concrete Strategy 3** | `GzipCompression` | `OllamaLanguageModel` |\n",
        "| **Context** | `FileCompressor` | `Annotator` (usa model.infer()) |\n",
        "| **Troca de estrat√©gia** | `set_strategy()` | Factory cria estrat√©gia correta |\n",
        "| **Algoritmo varia** | ‚úÖ SIM (ZIP vs RAR vs GZIP) | ‚úÖ SIM (Gemini vs OpenAI vs Ollama) |\n",
        "| **Interface comum** | ‚úÖ SIM | ‚úÖ SIM (infer + parse_output) |\n",
        "| **Polimorfismo** | ‚úÖ SIM | ‚úÖ SIM (BaseLanguageModel) |\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ **4. MAPEAMENTO CONCEITUAL**\n",
        "\n",
        "```\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ  PADR√ÉO GoF                ‚Üí    LANGEXTRACT                ‚îÇ\n",
        "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
        "‚îÇ  Strategy (interface)      ‚Üí    BaseLanguageModel          ‚îÇ\n",
        "‚îÇ  compress() abstrato       ‚Üí    infer() abstrato           ‚îÇ\n",
        "‚îÇ  ConcreteStrategyA         ‚Üí    GeminiLanguageModel        ‚îÇ\n",
        "‚îÇ  ConcreteStrategyB         ‚Üí    OpenAILanguageModel        ‚îÇ\n",
        "‚îÇ  ConcreteStrategyC         ‚Üí    OllamaLanguageModel        ‚îÇ\n",
        "‚îÇ  Context                   ‚Üí    Annotator                  ‚îÇ\n",
        "‚îÇ  set_strategy()            ‚Üí    create_model(config)       ‚îÇ\n",
        "‚îÇ  Cliente escolhe           ‚Üí    ModelConfig especifica     ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "```\n",
        "\n",
        "### **Fluxo de Execu√ß√£o**\n",
        "\n",
        "```\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ  Cliente (extract)   ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "           ‚îÇ\n",
        "           ‚îÇ ModelConfig(model_id=\"gemini-2.5-flash\")\n",
        "           ‚îÇ\n",
        "           ‚ñº\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ  Factory             ‚îÇ\n",
        "‚îÇ  create_model()      ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "           ‚îÇ\n",
        "           ‚îÇ Cria estrat√©gia apropriada\n",
        "           ‚îÇ\n",
        "           ‚ñº\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ  BaseLanguageModel (Strategy Interface)     ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "           ‚îÇ\n",
        "           ‚îú‚îÄ‚îÄ‚îÄ GeminiLanguageModel\n",
        "           ‚îÇ    ‚îî‚îÄ infer() ‚Üí google.genai SDK\n",
        "           ‚îÇ\n",
        "           ‚îú‚îÄ‚îÄ‚îÄ OpenAILanguageModel\n",
        "           ‚îÇ    ‚îî‚îÄ infer() ‚Üí openai SDK\n",
        "           ‚îÇ\n",
        "           ‚îî‚îÄ‚îÄ‚îÄ OllamaLanguageModel\n",
        "                ‚îî‚îÄ infer() ‚Üí HTTP requests\n",
        "           ‚îÇ\n",
        "           ‚ñº\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ  Annotator (Context) ‚îÇ\n",
        "‚îÇ  model.infer(prompt) ‚îÇ  ‚óÑ‚îÄ‚îÄ‚îÄ Usa estrat√©gia polimorficamente\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üí° **5. EXEMPLO PR√ÅTICO COMPLETO**\n",
        "\n",
        "### **A) Strategy Cl√°ssico (Pagamento)**\n",
        "\n",
        "```python\n",
        "from abc import ABC, abstractmethod\n",
        "\n",
        "# ============================================\n",
        "# STRATEGY INTERFACE\n",
        "# ============================================\n",
        "\n",
        "class PaymentStrategy(ABC):\n",
        "    @abstractmethod\n",
        "    def pay(self, amount: float) -> str:\n",
        "        pass\n",
        "\n",
        "# ============================================\n",
        "# CONCRETE STRATEGIES\n",
        "# ============================================\n",
        "\n",
        "class CreditCardPayment(PaymentStrategy):\n",
        "    def __init__(self, card_number: str):\n",
        "        self.card_number = card_number\n",
        "    \n",
        "    def pay(self, amount: float) -> str:\n",
        "        return f\"Paid ${amount} with Credit Card {self.card_number}\"\n",
        "\n",
        "class PayPalPayment(PaymentStrategy):\n",
        "    def __init__(self, email: str):\n",
        "        self.email = email\n",
        "    \n",
        "    def pay(self, amount: float) -> str:\n",
        "        return f\"Paid ${amount} with PayPal {self.email}\"\n",
        "\n",
        "class BitcoinPayment(PaymentStrategy):\n",
        "    def __init__(self, wallet_address: str):\n",
        "        self.wallet_address = wallet_address\n",
        "    \n",
        "    def pay(self, amount: float) -> str:\n",
        "        return f\"Paid ${amount} with Bitcoin {self.wallet_address}\"\n",
        "\n",
        "# ============================================\n",
        "# CONTEXT\n",
        "# ============================================\n",
        "\n",
        "class ShoppingCart:\n",
        "    def __init__(self):\n",
        "        self._items = []\n",
        "        self._payment_strategy: PaymentStrategy | None = None\n",
        "    \n",
        "    def add_item(self, item: str, price: float):\n",
        "        self._items.append((item, price))\n",
        "    \n",
        "    def set_payment_strategy(self, strategy: PaymentStrategy):\n",
        "        \"\"\"Troca estrat√©gia de pagamento\"\"\"\n",
        "        self._payment_strategy = strategy\n",
        "    \n",
        "    def checkout(self) -> str:\n",
        "        \"\"\"Usa estrat√©gia atual para pagamento\"\"\"\n",
        "        total = sum(price for _, price in self._items)\n",
        "        \n",
        "        if not self._payment_strategy:\n",
        "            raise ValueError(\"No payment strategy set\")\n",
        "        \n",
        "        return self._payment_strategy.pay(total)\n",
        "\n",
        "# ============================================\n",
        "# USO\n",
        "# ============================================\n",
        "\n",
        "cart = ShoppingCart()\n",
        "cart.add_item(\"Book\", 29.99)\n",
        "cart.add_item(\"Pen\", 1.50)\n",
        "\n",
        "# Cliente 1: Paga com cart√£o\n",
        "cart.set_payment_strategy(CreditCardPayment(\"1234-5678-9012-3456\"))\n",
        "print(cart.checkout())  # Paid $31.49 with Credit Card 1234-...\n",
        "\n",
        "# Cliente 2: Troca para PayPal\n",
        "cart.set_payment_strategy(PayPalPayment(\"user@example.com\"))\n",
        "print(cart.checkout())  # Paid $31.49 with PayPal user@example.com\n",
        "\n",
        "# Cliente 3: Troca para Bitcoin\n",
        "cart.set_payment_strategy(BitcoinPayment(\"1A1zP1eP5QGefi2DMPTfTL5SLmv7DivfNa\"))\n",
        "print(cart.checkout())  # Paid $31.49 with Bitcoin 1A1z...\n",
        "```\n",
        "\n",
        "### **B) LangExtract Strategy (Real)**\n",
        "\n",
        "```python\n",
        "# ============================================\n",
        "# USO NO LANGEXTRACT\n",
        "# ============================================\n",
        "\n",
        "import langextract as lx\n",
        "\n",
        "# ============================================\n",
        "# ESTRAT√âGIA 1: Gemini\n",
        "# ============================================\n",
        "\n",
        "result1 = lx.extract(\n",
        "    text_or_documents=\"Extract info from this text\",\n",
        "    model_id=\"gemini-2.5-flash\",  # ‚Üê Factory escolhe GeminiLanguageModel\n",
        "    api_key=\"...\",\n",
        "    prompt_description=\"Extract entities\"\n",
        ")\n",
        "# Internamente:\n",
        "# - Factory cria GeminiLanguageModel\n",
        "# - Annotator chama model.infer()\n",
        "# - GeminiLanguageModel.infer() usa google-genai SDK\n",
        "\n",
        "# ============================================\n",
        "# ESTRAT√âGIA 2: OpenAI (troca em runtime)\n",
        "# ============================================\n",
        "\n",
        "result2 = lx.extract(\n",
        "    text_or_documents=\"Same text\",\n",
        "    model_id=\"gpt-4o-mini\",  # ‚Üê Factory escolhe OpenAILanguageModel\n",
        "    api_key=\"...\",\n",
        "    prompt_description=\"Extract entities\"\n",
        ")\n",
        "# Internamente:\n",
        "# - Factory cria OpenAILanguageModel\n",
        "# - Annotator chama model.infer()\n",
        "# - OpenAILanguageModel.infer() usa openai SDK\n",
        "\n",
        "# ============================================\n",
        "# ESTRAT√âGIA 3: Ollama (local)\n",
        "# ============================================\n",
        "\n",
        "result3 = lx.extract(\n",
        "    text_or_documents=\"Same text\",\n",
        "    model_id=\"llama3.2:1b\",  # ‚Üê Factory escolhe OllamaLanguageModel\n",
        "    prompt_description=\"Extract entities\"\n",
        ")\n",
        "# Internamente:\n",
        "# - Factory cria OllamaLanguageModel\n",
        "# - Annotator chama model.infer()\n",
        "# - OllamaLanguageModel.infer() usa HTTP requests\n",
        "\n",
        "# ============================================\n",
        "# POLIMORFISMO EM A√á√ÉO\n",
        "# ============================================\n",
        "\n",
        "from langextract.core.base_model import BaseLanguageModel\n",
        "\n",
        "def process_with_any_model(model: BaseLanguageModel, prompt: str):\n",
        "    \"\"\"Aceita QUALQUER estrat√©gia (Gemini, OpenAI, Ollama)\"\"\"\n",
        "    outputs = list(model.infer([prompt]))\n",
        "    return outputs[0][0].output\n",
        "\n",
        "# Funciona com todas as estrat√©gias:\n",
        "gemini_model = GeminiLanguageModel(api_key=\"...\")\n",
        "openai_model = OpenAILanguageModel(api_key=\"...\")\n",
        "ollama_model = OllamaLanguageModel(model_id=\"llama3.2:1b\")\n",
        "\n",
        "result_a = process_with_any_model(gemini_model, \"Extract...\")\n",
        "result_b = process_with_any_model(openai_model, \"Extract...\")\n",
        "result_c = process_with_any_model(ollama_model, \"Extract...\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ **6. CHECKLIST DE VERIFICA√á√ÉO**\n",
        "\n",
        "| Caracter√≠stica do Strategy Pattern | LangExtract |\n",
        "|-------------------------------------|-------------|\n",
        "| ‚úÖ Interface abstrata com m√©todo abstrato | ‚úÖ SIM (`BaseLanguageModel.infer()`) |\n",
        "| ‚úÖ M√∫ltiplas implementa√ß√µes concretas | ‚úÖ SIM (Gemini, OpenAI, Ollama) |\n",
        "| ‚úÖ Algoritmo varia entre estrat√©gias | ‚úÖ SIM (SDK vs HTTP, parallel vs sequential) |\n",
        "| ‚úÖ Interface comum para todas | ‚úÖ SIM (`infer()` assinatura id√™ntica) |\n",
        "| ‚úÖ Polimorfismo em tempo de execu√ß√£o | ‚úÖ SIM (Annotator usa BaseLanguageModel) |\n",
        "| ‚úÖ Estrat√©gias intercambi√°veis | ‚úÖ SIM (Factory cria estrat√©gia certa) |\n",
        "| ‚úÖ Cliente n√£o conhece implementa√ß√£o | ‚úÖ SIM (Annotator n√£o sabe se √© Gemini/OpenAI) |\n",
        "| ‚úÖ Facilita adi√ß√£o de novas estrat√©gias | ‚úÖ SIM (basta herdar BaseLanguageModel) |\n",
        "\n",
        "---\n",
        "\n",
        "## üìà **7. COMPARA√á√ÉO DE ALGORITMOS**\n",
        "\n",
        "### **Diferen√ßas entre Estrat√©gias**\n",
        "\n",
        "| Aspecto | GeminiLanguageModel | OpenAILanguageModel | OllamaLanguageModel |\n",
        "|---------|---------------------|---------------------|---------------------|\n",
        "| **SDK** | google-genai | openai | requests (HTTP) |\n",
        "| **Endpoint** | genai.Client | chat.completions | POST /api/generate |\n",
        "| **JSON mode** | response_schema | response_format | format: 'json' |\n",
        "| **Parallel** | ‚úÖ ThreadPoolExecutor | ‚úÖ ThreadPoolExecutor | ‚ùå Sequential |\n",
        "| **Auth** | api_key ou Vertex AI | api_key | Opcional (local) |\n",
        "| **Structured output** | ‚úÖ Native (schema_dict) | ‚ö†Ô∏è JSON mode only | ‚ö†Ô∏è JSON mode only |\n",
        "| **Timeout** | Configur√°vel | Configur√°vel | Configur√°vel |\n",
        "| **Streaming** | ‚ùå N√£o (batch) | ‚ùå N√£o (batch) | ‚ùå N√£o (stream=False) |\n",
        "\n",
        "### **Exemplo de Diferen√ßa de Algoritmo**\n",
        "\n",
        "```python\n",
        "# ============================================\n",
        "# GEMINI: Parallel processing\n",
        "# ============================================\n",
        "\n",
        "def infer(self, batch_prompts):\n",
        "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
        "        futures = {\n",
        "            executor.submit(self._process_single_prompt, p): i\n",
        "            for i, p in enumerate(batch_prompts)\n",
        "        }\n",
        "        # Processa todos em paralelo\n",
        "        for future in as_completed(futures):\n",
        "            yield [future.result()]\n",
        "\n",
        "# ============================================\n",
        "# OPENAI: Parallel processing similar\n",
        "# ============================================\n",
        "\n",
        "def infer(self, batch_prompts):\n",
        "    # Mesma estrutura de Gemini\n",
        "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
        "        # ... parallel processing\n",
        "\n",
        "# ============================================\n",
        "# OLLAMA: Sequential processing\n",
        "# ============================================\n",
        "\n",
        "def infer(self, batch_prompts):\n",
        "    # Sem parallel processing\n",
        "    for prompt in batch_prompts:\n",
        "        response = self._ollama_query(prompt, ...)\n",
        "        yield [ScoredOutput(output=response['response'])]\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üîß **8. VANTAGENS DA IMPLEMENTA√á√ÉO**\n",
        "\n",
        "| Vantagem | Descri√ß√£o |\n",
        "|----------|-----------|\n",
        "| **Intercambi√°vel** | Troca entre Gemini/OpenAI/Ollama sem mudar c√≥digo cliente |\n",
        "| **Extens√≠vel** | Nova estrat√©gia = nova classe herda BaseLanguageModel |\n",
        "| **Test√°vel** | Pode criar MockLanguageModel para testes |\n",
        "| **Encapsulamento** | Detalhes de API (SDK, HTTP) ocultos do cliente |\n",
        "| **Polim√≥rfico** | Annotator usa BaseLanguageModel (n√£o importa qual) |\n",
        "| **Configur√°vel** | Cada estrat√©gia tem seus par√¢metros espec√≠ficos |\n",
        "\n",
        "---\n",
        "\n",
        "## üÜï **9. ADICIONANDO NOVA ESTRAT√âGIA**\n",
        "\n",
        "### **Como adicionar novo provider (ex: Anthropic Claude)**\n",
        "\n",
        "```python\n",
        "# ============================================\n",
        "# NOVA ESTRAT√âGIA: AnthropicLanguageModel\n",
        "# ============================================\n",
        "\n",
        "from langextract.core import base_model\n",
        "from langextract.providers import router\n",
        "\n",
        "@router.register(\"claude-*\", priority=5)  # Registra padr√£o\n",
        "class AnthropicLanguageModel(base_model.BaseLanguageModel):\n",
        "    \"\"\"\n",
        "    NOVA CONCRETE STRATEGY: Anthropic Claude.\n",
        "    \n",
        "    Algoritmo espec√≠fico:\n",
        "    - Usa anthropic SDK\n",
        "    - Messages API\n",
        "    \"\"\"\n",
        "    \n",
        "    model_id: str = \"claude-3-5-sonnet-20241022\"\n",
        "    api_key: str | None = None\n",
        "    \n",
        "    def __init__(\n",
        "        self,\n",
        "        model_id: str = \"claude-3-5-sonnet-20241022\",\n",
        "        api_key: str | None = None,\n",
        "        **kwargs\n",
        "    ):\n",
        "        \"\"\"Inicializa cliente Anthropic\"\"\"\n",
        "        import anthropic\n",
        "        \n",
        "        self.model_id = model_id\n",
        "        self.api_key = api_key\n",
        "        \n",
        "        # Cliente Anthropic SDK\n",
        "        self._client = anthropic.Anthropic(api_key=api_key)\n",
        "        \n",
        "        super().__init__(constraint=schema.Constraint())\n",
        "    \n",
        "    def infer(\n",
        "        self,\n",
        "        batch_prompts: Sequence[str],\n",
        "        **kwargs\n",
        "    ) -> Iterator[Sequence[core_types.ScoredOutput]]:\n",
        "        \"\"\"\n",
        "        ALGORITMO ANTHROPIC: Infer√™ncia via Anthropic SDK.\n",
        "        \n",
        "        Espec√≠fico do Claude:\n",
        "        - Messages API\n",
        "        - System prompts\n",
        "        - Temperature, max_tokens\n",
        "        \"\"\"\n",
        "        for prompt in batch_prompts:\n",
        "            response = self._client.messages.create(\n",
        "                model=self.model_id,\n",
        "                max_tokens=kwargs.get('max_tokens', 1024),\n",
        "                temperature=kwargs.get('temperature', 0.0),\n",
        "                messages=[{\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": prompt\n",
        "                }]\n",
        "            )\n",
        "            \n",
        "            output = response.content[0].text\n",
        "            yield [core_types.ScoredOutput(score=1.0, output=output)]\n",
        "\n",
        "# ============================================\n",
        "# USO IMEDIATO\n",
        "# ============================================\n",
        "\n",
        "import langextract as lx\n",
        "\n",
        "result = lx.extract(\n",
        "    text_or_documents=\"Extract entities\",\n",
        "    model_id=\"claude-3-5-sonnet-20241022\",  # ‚Üê Factory detecta automaticamente\n",
        "    api_key=\"sk-ant-...\",\n",
        "    prompt_description=\"Extract names\"\n",
        ")\n",
        "# Funciona! Factory cria AnthropicLanguageModel via @router.register\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üìù **10. CONCLUS√ÉO**\n",
        "\n",
        "### **‚úÖ √â Strategy Pattern? SIM! 100% GoF Compliant**\n",
        "\n",
        "**Evid√™ncias:**\n",
        "\n",
        "1. ‚úÖ **Interface abstrata** - `BaseLanguageModel(ABC)` com `@abstractmethod infer()`\n",
        "2. ‚úÖ **M√∫ltiplas estrat√©gias** - Gemini, OpenAI, Ollama (+ extens√≠vel)\n",
        "3. ‚úÖ **Algoritmo intercambi√°vel** - SDK google-genai vs openai vs HTTP\n",
        "4. ‚úÖ **Polimorfismo** - Annotator usa `BaseLanguageModel` (n√£o conhece implementa√ß√£o)\n",
        "5. ‚úÖ **Troca em runtime** - Factory cria estrat√©gia baseado em `model_id`\n",
        "6. ‚úÖ **Interface comum** - Todas implementam `infer()` com mesma assinatura\n",
        "7. ‚úÖ **Comportamento varia** - Parallel (Gemini) vs Sequential (Ollama)\n",
        "\n",
        "### **Classifica√ß√£o:**\n",
        "üèÜ **Strategy Pattern (GoF) - Implementa√ß√£o Pura e Completa**\n",
        "\n",
        "### **Por que √© Strategy perfeito?**\n",
        "\n",
        "```\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ  OBJETIVO DO PADR√ÉO                        ‚îÇ\n",
        "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
        "‚îÇ  \"Permitir que algoritmo varie             ‚îÇ\n",
        "‚îÇ   independentemente dos clientes\"          ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                    ‚îÇ\n",
        "                    ‚îÇ\n",
        "                    ‚ñº\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ  LANGEXTRACT IMPLEMENTA√á√ÉO                 ‚îÇ\n",
        "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
        "‚îÇ  ‚úÖ Annotator (cliente) n√£o sabe qual LLM  ‚îÇ\n",
        "‚îÇ  ‚úÖ GeminiLanguageModel.infer() ‚â†          ‚îÇ\n",
        "‚îÇ      OpenAILanguageModel.infer()           ‚îÇ\n",
        "‚îÇ  ‚úÖ Mesma interface, algoritmos diferentes ‚îÇ\n",
        "‚îÇ  ‚úÖ F√°cil adicionar nova estrat√©gia        ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "```\n",
        "\n",
        "### **Evid√™ncia Visual:**\n",
        "\n",
        "```python\n",
        "# ============================================\n",
        "# SEM STRATEGY (‚ùå C√≥digo acoplado)\n",
        "# ============================================\n",
        "\n",
        "def extract(text, provider):\n",
        "    if provider == \"gemini\":\n",
        "        from google import genai\n",
        "        client = genai.Client(api_key=\"...\")\n",
        "        response = client.models.generate_content(...)\n",
        "        return response.text\n",
        "    elif provider == \"openai\":\n",
        "        import openai\n",
        "        client = openai.OpenAI(api_key=\"...\")\n",
        "        response = client.chat.completions.create(...)\n",
        "        return response.choices[0].message.content\n",
        "    elif provider == \"ollama\":\n",
        "        import requests\n",
        "        response = requests.post(\"http://localhost:11434/api/generate\", ...)\n",
        "        return response.json()['response']\n",
        "    # ‚ùå Dif√≠cil manter, adicionar novos providers\n",
        "\n",
        "# ============================================\n",
        "# COM STRATEGY (‚úÖ Desacoplado)\n",
        "# ============================================\n",
        "\n",
        "def extract(text, model: BaseLanguageModel):\n",
        "    \"\"\"Aceita QUALQUER estrat√©gia\"\"\"\n",
        "    outputs = model.infer([text])\n",
        "    return list(outputs)[0][0].output\n",
        "\n",
        "# Uso com qualquer provider:\n",
        "extract(text, GeminiLanguageModel(api_key=\"...\"))\n",
        "extract(text, OpenAILanguageModel(api_key=\"...\"))\n",
        "extract(text, OllamaLanguageModel(model_id=\"llama3.2\"))\n",
        "# ‚úÖ F√°cil adicionar AnthropicLanguageModel\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "q8o_OGnEfaDw"
      }
    }
  ]
}